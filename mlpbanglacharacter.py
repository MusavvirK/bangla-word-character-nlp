# -*- coding: utf-8 -*-
"""MLPBanglaCharacter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Yh-VYvWOxBDmgXnYb7TBLoPuZ9MPJE0I
"""

import numpy as np
import pandas as pd

from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import Adam, SGD, RMSprop
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split

def wordCharacterToUnicode(arr, arrOutput):
  for i in range(0, len(arr)):
    temp = arr[i];
    count = 0
    for j in temp:
      arrOutput[i][count]= ord(j) - 2400
      count = count + 1

def labelToDataframe(arry, arryoutput):
  for i in range (0, len(arry)):
    for j in range (0, len(arry[i])):
      temp = arry[i][j]
      if (temp!= None):
        arryoutput.loc[i][temp] = 1

data = pd.read_csv('inputbn.csv', sep=',', engine='python', header=0)
data = data.to_numpy()

x_sample = data[:,0]
y_sample = data[:,1:10]
temp = np.zeros(shape = (100, 46))

X = np.zeros(shape = (100, 10))
wordCharacterToUnicode(x_sample, X)
temp = np.zeros(shape = (100, 46))
df = pd.DataFrame(temp, columns=['অ','আ','ই','ঈ','উ','ঊ','ঋ','এ','ঐ','ও','ঔ','ক','খ','গ','ঘ','ঙ','চ','ছ','জ','ঝ','ঞ','ট','ঠ','ড','ঢ','ণ','ত','থ','দ','ধ','ন','প','ফ','ব','ভ','ম','য','র','ল','শ','ষ','স','হ','ড়','ঢ়','য়'])
labelToDataframe(y_sample, df)
print(X[0:5])
print(df.head(5))

trainX, testX, trainy, testy = train_test_split(X, df, test_size=0.4)

#define model
model = Sequential()
model.add(Dense(128, input_shape=(10,), activation='relu'))
model.add(Dense(70, activation='relu'))
model.add(Dense(46, activation='sigmoid'))
model.summary()

# compile model
opt = Adam(lr=0.001)
model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])

#fit model (train)
history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=2)

# evaluate the keras model
loss, accuracy = model.evaluate(X, df)
print("\nLoss: %.3f, Accuracy: %.2f%%" % (loss, accuracy*100))

history_dict = history.history
history_dict.keys()

import matplotlib.pyplot as plt

acc = history_dict['acc']
loss = history_dict['loss']
epochs = range(1, len(loss) + 1)

# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.title('Training loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

plt.clf()   # clear figure

plt.plot(epochs, acc, color='darkblue', label='Training acc' )
plt.title('Training accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')

plt.show()

tempString = 'সরকারি'
Y = [0,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0]
tempInput = np.zeros(shape=(1,10))
count = 0
for i in tempString:
  tempInput[0][count]= ord(i) - 2400
  count = count + 1
print(tempInput)
probabilities = model.predict(tempInput)
prediction = pd.DataFrame(probabilities, columns=['অ','আ','ই','ঈ','উ','ঊ','ঋ','এ','ঐ','ও','ঔ','ক','খ','গ','ঘ','ঙ','চ','ছ','জ','ঝ','ঞ','ট','ঠ','ড','ঢ','ণ','ত','থ','দ','ধ','ন','প','ফ','ব','ভ','ম','য','র','ল','শ','ষ','স','হ','ড়','ঢ়','য়'])
accuracy = np.mean(probabilities == Y)
print(prediction)