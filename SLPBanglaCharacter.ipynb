{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SLPBanglaCharacter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pd2N0ES1j10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "608fdea2-4876-4513-aba1-ea53c5a8abbc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "bornoDict =\t{\n",
        "  'অ': 1,\n",
        "  'আ': 2,\n",
        "  'ই': 3,\n",
        "  'ঈ': 4,\n",
        "  'উ': 5,\n",
        "  'ঊ': 6,\n",
        "  'ঋ': 7,\n",
        "  'এ': 8,\n",
        "  'ঐ': 9,\n",
        "  'ও': 10,\n",
        "  'ঔ': 11,\n",
        "  'ক': 12,\n",
        "  'খ': 13,\n",
        "  'গ': 14,\n",
        "  'ঘ': 15,\n",
        "  'ঙ': 16,\n",
        "  'চ': 17,\n",
        "  'ছ': 18,\n",
        "  'জ': 19,\n",
        "  'ঝ': 20,\n",
        "  'ঞ': 21,\n",
        "  'ট': 22,\n",
        "  'ঠ': 23,\n",
        "  'ড': 24,\n",
        "  'ঢ': 25,\n",
        "  'ণ': 26,\n",
        "  'ত': 27,\n",
        "  'থ': 28,\n",
        "  'দ': 29,\n",
        "  'ধ': 30,\n",
        "  'ন': 31,\n",
        "  'প': 32,\n",
        "  'ফ': 33,\n",
        "  'ব': 34,\n",
        "  'ভ': 35,\n",
        "  'ম': 36,\n",
        "  'য': 37,\n",
        "  'র': 38,\n",
        "  'ল': 39,\n",
        "  'শ': 40,\n",
        "  'ষ': 41,\n",
        "  'স': 42,\n",
        "  'হ': 43,\n",
        "  'ড়': 44,\n",
        "  'ঢ়': 45,\n",
        "  'য়': 46\n",
        "}\n",
        "\n",
        "def wordCharacterToUnicode(arr, arrOutput):\n",
        "  for i in range(0, len(arr)):\n",
        "    temp = arr[i];\n",
        "    count = 0\n",
        "    for j in temp:\n",
        "      arrOutput[i][count]= ord(j) - 2400\n",
        "      count = count + 1\n",
        "\n",
        "def labelCharacterToInteger(arry, arryoutput):\n",
        "  for i in range (0, len(arry)):\n",
        "        arryoutput[i]= bornoDict[arry[i]]\n",
        "\n",
        "\n",
        "data = pd.read_csv('inputbn.csv', sep=',', engine='python', header=0)\n",
        "data = data.to_numpy()\n",
        "\n",
        "x_sample = data[:,0]\n",
        "y_sample = data[:,1]\n",
        "\n",
        "X = np.zeros(shape = (100, 10))\n",
        "wordCharacterToUnicode(x_sample, X)\n",
        "Y = np.zeros(shape = (100, 1))\n",
        "labelCharacterToInteger(y_sample, Y)\n",
        "print(X[0:5])\n",
        "print(Y[0:5])\n",
        "\n",
        "trainX, testX, trainy, testy = train_test_split(X, Y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 76.  82.  94.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [ 53.  69.  94.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [ 39.  82.  95.  86.   0.   0.   0.   0.   0.   0.]\n",
            " [ 76.  94.  82.  95.  53.  94.   0.   0.   0.   0.]\n",
            " [ 78.  72. 103.   0.   0.   0.   0.   0.   0.   0.]]\n",
            "[[34.]\n",
            " [12.]\n",
            " [ 3.]\n",
            " [34.]\n",
            " [36.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAoo0LjNq3pW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c981287c-b9ba-44c4-87e3-30bc134ef500"
      },
      "source": [
        "opt = Adam(lr = 0.001)\n",
        "model = Sequential()\n",
        "model.add(Dense(output_dim=1, init='uniform', activation='relu', input_dim=10))\n",
        "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), batch_size=2, epochs=1000, verbose=2)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, units=1, kernel_initializer=\"uniform\")`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 9s - loss: 366.8370 - acc: 0.0875 - val_loss: 175.2834 - val_acc: 0.2000\n",
            "Epoch 2/1000\n",
            " - 0s - loss: 158.7220 - acc: 0.1125 - val_loss: 163.7816 - val_acc: 0.1500\n",
            "Epoch 3/1000\n",
            " - 0s - loss: 124.3758 - acc: 0.1000 - val_loss: 164.7019 - val_acc: 0.2500\n",
            "Epoch 4/1000\n",
            " - 0s - loss: 116.4751 - acc: 0.1000 - val_loss: 151.1381 - val_acc: 0.1500\n",
            "Epoch 5/1000\n",
            " - 0s - loss: 109.0578 - acc: 0.1250 - val_loss: 131.9166 - val_acc: 0.2000\n",
            "Epoch 6/1000\n",
            " - 0s - loss: 103.4602 - acc: 0.1250 - val_loss: 128.5111 - val_acc: 0.2000\n",
            "Epoch 7/1000\n",
            " - 0s - loss: 98.8945 - acc: 0.1375 - val_loss: 126.0930 - val_acc: 0.1500\n",
            "Epoch 8/1000\n",
            " - 0s - loss: 94.9510 - acc: 0.1375 - val_loss: 115.2798 - val_acc: 0.1500\n",
            "Epoch 9/1000\n",
            " - 0s - loss: 93.0809 - acc: 0.1250 - val_loss: 115.1352 - val_acc: 0.2000\n",
            "Epoch 10/1000\n",
            " - 0s - loss: 90.2047 - acc: 0.1000 - val_loss: 111.0212 - val_acc: 0.2000\n",
            "Epoch 11/1000\n",
            " - 0s - loss: 87.0901 - acc: 0.1000 - val_loss: 110.7544 - val_acc: 0.2000\n",
            "Epoch 12/1000\n",
            " - 0s - loss: 85.7946 - acc: 0.1000 - val_loss: 102.4295 - val_acc: 0.2500\n",
            "Epoch 13/1000\n",
            " - 0s - loss: 83.8841 - acc: 0.1000 - val_loss: 101.2660 - val_acc: 0.2000\n",
            "Epoch 14/1000\n",
            " - 0s - loss: 81.4089 - acc: 0.1000 - val_loss: 102.8062 - val_acc: 0.1500\n",
            "Epoch 15/1000\n",
            " - 0s - loss: 79.6136 - acc: 0.1000 - val_loss: 104.0649 - val_acc: 0.2500\n",
            "Epoch 16/1000\n",
            " - 0s - loss: 77.9416 - acc: 0.1000 - val_loss: 97.8783 - val_acc: 0.2000\n",
            "Epoch 17/1000\n",
            " - 0s - loss: 75.3806 - acc: 0.0875 - val_loss: 96.5045 - val_acc: 0.2000\n",
            "Epoch 18/1000\n",
            " - 0s - loss: 74.9654 - acc: 0.0875 - val_loss: 96.0711 - val_acc: 0.2000\n",
            "Epoch 19/1000\n",
            " - 0s - loss: 71.8613 - acc: 0.1125 - val_loss: 89.4078 - val_acc: 0.2000\n",
            "Epoch 20/1000\n",
            " - 0s - loss: 72.0840 - acc: 0.1250 - val_loss: 91.2781 - val_acc: 0.2000\n",
            "Epoch 21/1000\n",
            " - 0s - loss: 68.8663 - acc: 0.1000 - val_loss: 87.2130 - val_acc: 0.2000\n",
            "Epoch 22/1000\n",
            " - 0s - loss: 67.2061 - acc: 0.0875 - val_loss: 88.2268 - val_acc: 0.2000\n",
            "Epoch 23/1000\n",
            " - 0s - loss: 65.7829 - acc: 0.1125 - val_loss: 84.2422 - val_acc: 0.2000\n",
            "Epoch 24/1000\n",
            " - 0s - loss: 64.0680 - acc: 0.0875 - val_loss: 82.7427 - val_acc: 0.2000\n",
            "Epoch 25/1000\n",
            " - 0s - loss: 62.8088 - acc: 0.0875 - val_loss: 80.7202 - val_acc: 0.2000\n",
            "Epoch 26/1000\n",
            " - 0s - loss: 61.8567 - acc: 0.0875 - val_loss: 85.2229 - val_acc: 0.2500\n",
            "Epoch 27/1000\n",
            " - 0s - loss: 60.5428 - acc: 0.1125 - val_loss: 80.3940 - val_acc: 0.2000\n",
            "Epoch 28/1000\n",
            " - 0s - loss: 59.5699 - acc: 0.1500 - val_loss: 76.4052 - val_acc: 0.1500\n",
            "Epoch 29/1000\n",
            " - 0s - loss: 59.7191 - acc: 0.0875 - val_loss: 73.9973 - val_acc: 0.2000\n",
            "Epoch 30/1000\n",
            " - 0s - loss: 56.4485 - acc: 0.1125 - val_loss: 74.6053 - val_acc: 0.1500\n",
            "Epoch 31/1000\n",
            " - 0s - loss: 55.5924 - acc: 0.1125 - val_loss: 73.6242 - val_acc: 0.2000\n",
            "Epoch 32/1000\n",
            " - 0s - loss: 54.4136 - acc: 0.1250 - val_loss: 71.0056 - val_acc: 0.1500\n",
            "Epoch 33/1000\n",
            " - 0s - loss: 53.1232 - acc: 0.1125 - val_loss: 71.0174 - val_acc: 0.1500\n",
            "Epoch 34/1000\n",
            " - 0s - loss: 52.6281 - acc: 0.1125 - val_loss: 69.5675 - val_acc: 0.2500\n",
            "Epoch 35/1000\n",
            " - 0s - loss: 50.9884 - acc: 0.1250 - val_loss: 65.4721 - val_acc: 0.2000\n",
            "Epoch 36/1000\n",
            " - 0s - loss: 50.5967 - acc: 0.1250 - val_loss: 66.4618 - val_acc: 0.2500\n",
            "Epoch 37/1000\n",
            " - 0s - loss: 49.3668 - acc: 0.1000 - val_loss: 64.8217 - val_acc: 0.2500\n",
            "Epoch 38/1000\n",
            " - 0s - loss: 47.6991 - acc: 0.1000 - val_loss: 62.3886 - val_acc: 0.2000\n",
            "Epoch 39/1000\n",
            " - 0s - loss: 46.2533 - acc: 0.1000 - val_loss: 59.0993 - val_acc: 0.2000\n",
            "Epoch 40/1000\n",
            " - 0s - loss: 45.6956 - acc: 0.1125 - val_loss: 61.2288 - val_acc: 0.2500\n",
            "Epoch 41/1000\n",
            " - 0s - loss: 44.6749 - acc: 0.1000 - val_loss: 59.8163 - val_acc: 0.2500\n",
            "Epoch 42/1000\n",
            " - 0s - loss: 43.7224 - acc: 0.0875 - val_loss: 57.5446 - val_acc: 0.2000\n",
            "Epoch 43/1000\n",
            " - 0s - loss: 43.5121 - acc: 0.1125 - val_loss: 54.0418 - val_acc: 0.2500\n",
            "Epoch 44/1000\n",
            " - 0s - loss: 42.3436 - acc: 0.1000 - val_loss: 54.3894 - val_acc: 0.2000\n",
            "Epoch 45/1000\n",
            " - 0s - loss: 41.1775 - acc: 0.1000 - val_loss: 53.6061 - val_acc: 0.2000\n",
            "Epoch 46/1000\n",
            " - 0s - loss: 40.1408 - acc: 0.1000 - val_loss: 53.4357 - val_acc: 0.2500\n",
            "Epoch 47/1000\n",
            " - 0s - loss: 39.1251 - acc: 0.1000 - val_loss: 52.1004 - val_acc: 0.2000\n",
            "Epoch 48/1000\n",
            " - 0s - loss: 38.9839 - acc: 0.0875 - val_loss: 50.8962 - val_acc: 0.2000\n",
            "Epoch 49/1000\n",
            " - 0s - loss: 37.7403 - acc: 0.1000 - val_loss: 50.6586 - val_acc: 0.2000\n",
            "Epoch 50/1000\n",
            " - 0s - loss: 37.5561 - acc: 0.0875 - val_loss: 49.0162 - val_acc: 0.2000\n",
            "Epoch 51/1000\n",
            " - 0s - loss: 36.2194 - acc: 0.1000 - val_loss: 46.4763 - val_acc: 0.2500\n",
            "Epoch 52/1000\n",
            " - 0s - loss: 35.3626 - acc: 0.1000 - val_loss: 48.5049 - val_acc: 0.2000\n",
            "Epoch 53/1000\n",
            " - 0s - loss: 34.9612 - acc: 0.1125 - val_loss: 45.1941 - val_acc: 0.2500\n",
            "Epoch 54/1000\n",
            " - 0s - loss: 34.9497 - acc: 0.1250 - val_loss: 48.9634 - val_acc: 0.1500\n",
            "Epoch 55/1000\n",
            " - 0s - loss: 33.8713 - acc: 0.1000 - val_loss: 42.5962 - val_acc: 0.2000\n",
            "Epoch 56/1000\n",
            " - 0s - loss: 33.0069 - acc: 0.1125 - val_loss: 47.2131 - val_acc: 0.1500\n",
            "Epoch 57/1000\n",
            " - 0s - loss: 32.3893 - acc: 0.1250 - val_loss: 40.1566 - val_acc: 0.2500\n",
            "Epoch 58/1000\n",
            " - 0s - loss: 31.7617 - acc: 0.1250 - val_loss: 41.6741 - val_acc: 0.2500\n",
            "Epoch 59/1000\n",
            " - 0s - loss: 31.5370 - acc: 0.1125 - val_loss: 43.2377 - val_acc: 0.1500\n",
            "Epoch 60/1000\n",
            " - 0s - loss: 30.1590 - acc: 0.1250 - val_loss: 40.3744 - val_acc: 0.2500\n",
            "Epoch 61/1000\n",
            " - 0s - loss: 30.4379 - acc: 0.1000 - val_loss: 40.1000 - val_acc: 0.2500\n",
            "Epoch 62/1000\n",
            " - 0s - loss: 30.9251 - acc: 0.1125 - val_loss: 39.1479 - val_acc: 0.2000\n",
            "Epoch 63/1000\n",
            " - 0s - loss: 29.1725 - acc: 0.1500 - val_loss: 36.9406 - val_acc: 0.2500\n",
            "Epoch 64/1000\n",
            " - 0s - loss: 28.4581 - acc: 0.1250 - val_loss: 38.2826 - val_acc: 0.2000\n",
            "Epoch 65/1000\n",
            " - 0s - loss: 27.6492 - acc: 0.0875 - val_loss: 35.6681 - val_acc: 0.2500\n",
            "Epoch 66/1000\n",
            " - 0s - loss: 26.8310 - acc: 0.1000 - val_loss: 35.2545 - val_acc: 0.2500\n",
            "Epoch 67/1000\n",
            " - 0s - loss: 26.5873 - acc: 0.1000 - val_loss: 32.4043 - val_acc: 0.2000\n",
            "Epoch 68/1000\n",
            " - 0s - loss: 26.2341 - acc: 0.1250 - val_loss: 32.1167 - val_acc: 0.2000\n",
            "Epoch 69/1000\n",
            " - 0s - loss: 25.7938 - acc: 0.1000 - val_loss: 32.8788 - val_acc: 0.2500\n",
            "Epoch 70/1000\n",
            " - 0s - loss: 25.0677 - acc: 0.1125 - val_loss: 33.9920 - val_acc: 0.1500\n",
            "Epoch 71/1000\n",
            " - 0s - loss: 24.5093 - acc: 0.0875 - val_loss: 33.7385 - val_acc: 0.1500\n",
            "Epoch 72/1000\n",
            " - 0s - loss: 24.0835 - acc: 0.1250 - val_loss: 28.4363 - val_acc: 0.2000\n",
            "Epoch 73/1000\n",
            " - 0s - loss: 23.7865 - acc: 0.1125 - val_loss: 34.9784 - val_acc: 0.1500\n",
            "Epoch 74/1000\n",
            " - 0s - loss: 23.3361 - acc: 0.1375 - val_loss: 29.1499 - val_acc: 0.3000\n",
            "Epoch 75/1000\n",
            " - 0s - loss: 23.4958 - acc: 0.1125 - val_loss: 33.1653 - val_acc: 0.1500\n",
            "Epoch 76/1000\n",
            " - 0s - loss: 22.3935 - acc: 0.1125 - val_loss: 25.7556 - val_acc: 0.2000\n",
            "Epoch 77/1000\n",
            " - 0s - loss: 22.6044 - acc: 0.1250 - val_loss: 26.5892 - val_acc: 0.2000\n",
            "Epoch 78/1000\n",
            " - 0s - loss: 21.7495 - acc: 0.1000 - val_loss: 29.5032 - val_acc: 0.1500\n",
            "Epoch 79/1000\n",
            " - 0s - loss: 21.2745 - acc: 0.0875 - val_loss: 27.4449 - val_acc: 0.2500\n",
            "Epoch 80/1000\n",
            " - 0s - loss: 20.8529 - acc: 0.1250 - val_loss: 28.7903 - val_acc: 0.1500\n",
            "Epoch 81/1000\n",
            " - 0s - loss: 20.7170 - acc: 0.1000 - val_loss: 25.1152 - val_acc: 0.3000\n",
            "Epoch 82/1000\n",
            " - 0s - loss: 20.0985 - acc: 0.1250 - val_loss: 27.5094 - val_acc: 0.1500\n",
            "Epoch 83/1000\n",
            " - 0s - loss: 19.7817 - acc: 0.1000 - val_loss: 26.1964 - val_acc: 0.1500\n",
            "Epoch 84/1000\n",
            " - 0s - loss: 19.4389 - acc: 0.1125 - val_loss: 25.9171 - val_acc: 0.1500\n",
            "Epoch 85/1000\n",
            " - 0s - loss: 19.3194 - acc: 0.1375 - val_loss: 21.5028 - val_acc: 0.2000\n",
            "Epoch 86/1000\n",
            " - 0s - loss: 19.0228 - acc: 0.1250 - val_loss: 25.9547 - val_acc: 0.1500\n",
            "Epoch 87/1000\n",
            " - 0s - loss: 18.6147 - acc: 0.1125 - val_loss: 25.0795 - val_acc: 0.1500\n",
            "Epoch 88/1000\n",
            " - 0s - loss: 18.1789 - acc: 0.1000 - val_loss: 23.7842 - val_acc: 0.1500\n",
            "Epoch 89/1000\n",
            " - 0s - loss: 18.2020 - acc: 0.1000 - val_loss: 24.1500 - val_acc: 0.1500\n",
            "Epoch 90/1000\n",
            " - 0s - loss: 17.7166 - acc: 0.1250 - val_loss: 23.9914 - val_acc: 0.1500\n",
            "Epoch 91/1000\n",
            " - 0s - loss: 17.7772 - acc: 0.1500 - val_loss: 22.1847 - val_acc: 0.2000\n",
            "Epoch 92/1000\n",
            " - 0s - loss: 16.8976 - acc: 0.1250 - val_loss: 21.3516 - val_acc: 0.3000\n",
            "Epoch 93/1000\n",
            " - 0s - loss: 17.0188 - acc: 0.1250 - val_loss: 19.4453 - val_acc: 0.3000\n",
            "Epoch 94/1000\n",
            " - 0s - loss: 16.7341 - acc: 0.1125 - val_loss: 20.7411 - val_acc: 0.2000\n",
            "Epoch 95/1000\n",
            " - 0s - loss: 16.2415 - acc: 0.1000 - val_loss: 20.1339 - val_acc: 0.3000\n",
            "Epoch 96/1000\n",
            " - 0s - loss: 15.8922 - acc: 0.1125 - val_loss: 21.2423 - val_acc: 0.2000\n",
            "Epoch 97/1000\n",
            " - 0s - loss: 15.5492 - acc: 0.1125 - val_loss: 20.3821 - val_acc: 0.2500\n",
            "Epoch 98/1000\n",
            " - 0s - loss: 15.6227 - acc: 0.1250 - val_loss: 18.3327 - val_acc: 0.3500\n",
            "Epoch 99/1000\n",
            " - 0s - loss: 15.3428 - acc: 0.1250 - val_loss: 20.1009 - val_acc: 0.2000\n",
            "Epoch 100/1000\n",
            " - 0s - loss: 14.8902 - acc: 0.1250 - val_loss: 16.9563 - val_acc: 0.3500\n",
            "Epoch 101/1000\n",
            " - 0s - loss: 15.1268 - acc: 0.1625 - val_loss: 18.9337 - val_acc: 0.2500\n",
            "Epoch 102/1000\n",
            " - 0s - loss: 14.7593 - acc: 0.1000 - val_loss: 18.3964 - val_acc: 0.2500\n",
            "Epoch 103/1000\n",
            " - 0s - loss: 13.9934 - acc: 0.1125 - val_loss: 19.3878 - val_acc: 0.1500\n",
            "Epoch 104/1000\n",
            " - 0s - loss: 13.9403 - acc: 0.1625 - val_loss: 15.4462 - val_acc: 0.3000\n",
            "Epoch 105/1000\n",
            " - 0s - loss: 14.1468 - acc: 0.1750 - val_loss: 20.6026 - val_acc: 0.1500\n",
            "Epoch 106/1000\n",
            " - 0s - loss: 13.9759 - acc: 0.1125 - val_loss: 18.4218 - val_acc: 0.2000\n",
            "Epoch 107/1000\n",
            " - 0s - loss: 13.3470 - acc: 0.1500 - val_loss: 15.9889 - val_acc: 0.3000\n",
            "Epoch 108/1000\n",
            " - 0s - loss: 13.2679 - acc: 0.1500 - val_loss: 17.9419 - val_acc: 0.2000\n",
            "Epoch 109/1000\n",
            " - 0s - loss: 13.2589 - acc: 0.1625 - val_loss: 16.4506 - val_acc: 0.2000\n",
            "Epoch 110/1000\n",
            " - 0s - loss: 13.2359 - acc: 0.1625 - val_loss: 15.7914 - val_acc: 0.2000\n",
            "Epoch 111/1000\n",
            " - 0s - loss: 12.5124 - acc: 0.1625 - val_loss: 16.2866 - val_acc: 0.2000\n",
            "Epoch 112/1000\n",
            " - 0s - loss: 12.4801 - acc: 0.1625 - val_loss: 14.7082 - val_acc: 0.2500\n",
            "Epoch 113/1000\n",
            " - 0s - loss: 12.3660 - acc: 0.1375 - val_loss: 17.2756 - val_acc: 0.2500\n",
            "Epoch 114/1000\n",
            " - 0s - loss: 12.7810 - acc: 0.1625 - val_loss: 15.1133 - val_acc: 0.2000\n",
            "Epoch 115/1000\n",
            " - 0s - loss: 11.9688 - acc: 0.1875 - val_loss: 18.9838 - val_acc: 0.2500\n",
            "Epoch 116/1000\n",
            " - 0s - loss: 11.6865 - acc: 0.1625 - val_loss: 13.0904 - val_acc: 0.3000\n",
            "Epoch 117/1000\n",
            " - 0s - loss: 11.9760 - acc: 0.2250 - val_loss: 14.3837 - val_acc: 0.1500\n",
            "Epoch 118/1000\n",
            " - 0s - loss: 11.6017 - acc: 0.1375 - val_loss: 19.0407 - val_acc: 0.3000\n",
            "Epoch 119/1000\n",
            " - 0s - loss: 11.4803 - acc: 0.1625 - val_loss: 12.7566 - val_acc: 0.2000\n",
            "Epoch 120/1000\n",
            " - 0s - loss: 11.6122 - acc: 0.1750 - val_loss: 14.6972 - val_acc: 0.3500\n",
            "Epoch 121/1000\n",
            " - 0s - loss: 11.1103 - acc: 0.2000 - val_loss: 14.5512 - val_acc: 0.2500\n",
            "Epoch 122/1000\n",
            " - 0s - loss: 10.9081 - acc: 0.1875 - val_loss: 13.0171 - val_acc: 0.2000\n",
            "Epoch 123/1000\n",
            " - 0s - loss: 11.2157 - acc: 0.1750 - val_loss: 15.6653 - val_acc: 0.3000\n",
            "Epoch 124/1000\n",
            " - 0s - loss: 10.9257 - acc: 0.2250 - val_loss: 16.8442 - val_acc: 0.3000\n",
            "Epoch 125/1000\n",
            " - 0s - loss: 11.2619 - acc: 0.2250 - val_loss: 14.7206 - val_acc: 0.3500\n",
            "Epoch 126/1000\n",
            " - 0s - loss: 10.6025 - acc: 0.1750 - val_loss: 12.3014 - val_acc: 0.2000\n",
            "Epoch 127/1000\n",
            " - 0s - loss: 10.5980 - acc: 0.2250 - val_loss: 13.0986 - val_acc: 0.3000\n",
            "Epoch 128/1000\n",
            " - 0s - loss: 10.4676 - acc: 0.1625 - val_loss: 11.8978 - val_acc: 0.3000\n",
            "Epoch 129/1000\n",
            " - 0s - loss: 10.1703 - acc: 0.2125 - val_loss: 16.8164 - val_acc: 0.3000\n",
            "Epoch 130/1000\n",
            " - 0s - loss: 10.1653 - acc: 0.1875 - val_loss: 13.4219 - val_acc: 0.3500\n",
            "Epoch 131/1000\n",
            " - 0s - loss: 10.0771 - acc: 0.1875 - val_loss: 12.3194 - val_acc: 0.3000\n",
            "Epoch 132/1000\n",
            " - 0s - loss: 10.1275 - acc: 0.2250 - val_loss: 18.5100 - val_acc: 0.1500\n",
            "Epoch 133/1000\n",
            " - 0s - loss: 9.8998 - acc: 0.1875 - val_loss: 10.9191 - val_acc: 0.3500\n",
            "Epoch 134/1000\n",
            " - 0s - loss: 9.7356 - acc: 0.2125 - val_loss: 12.8631 - val_acc: 0.2500\n",
            "Epoch 135/1000\n",
            " - 0s - loss: 9.5287 - acc: 0.2375 - val_loss: 15.5952 - val_acc: 0.2500\n",
            "Epoch 136/1000\n",
            " - 0s - loss: 9.6575 - acc: 0.2000 - val_loss: 14.3583 - val_acc: 0.3000\n",
            "Epoch 137/1000\n",
            " - 0s - loss: 9.4011 - acc: 0.2125 - val_loss: 14.0425 - val_acc: 0.2500\n",
            "Epoch 138/1000\n",
            " - 0s - loss: 9.5390 - acc: 0.2250 - val_loss: 14.1097 - val_acc: 0.3000\n",
            "Epoch 139/1000\n",
            " - 0s - loss: 9.4779 - acc: 0.2000 - val_loss: 11.1800 - val_acc: 0.2500\n",
            "Epoch 140/1000\n",
            " - 0s - loss: 9.6452 - acc: 0.1375 - val_loss: 10.7418 - val_acc: 0.3000\n",
            "Epoch 141/1000\n",
            " - 0s - loss: 8.9897 - acc: 0.1500 - val_loss: 15.7418 - val_acc: 0.1500\n",
            "Epoch 142/1000\n",
            " - 0s - loss: 9.2782 - acc: 0.1750 - val_loss: 13.3538 - val_acc: 0.3500\n",
            "Epoch 143/1000\n",
            " - 0s - loss: 9.1918 - acc: 0.2000 - val_loss: 14.3527 - val_acc: 0.1500\n",
            "Epoch 144/1000\n",
            " - 0s - loss: 9.1105 - acc: 0.2375 - val_loss: 14.2851 - val_acc: 0.2500\n",
            "Epoch 145/1000\n",
            " - 0s - loss: 8.9928 - acc: 0.2250 - val_loss: 11.3942 - val_acc: 0.2500\n",
            "Epoch 146/1000\n",
            " - 0s - loss: 8.8971 - acc: 0.2000 - val_loss: 13.5397 - val_acc: 0.3000\n",
            "Epoch 147/1000\n",
            " - 0s - loss: 9.0052 - acc: 0.1625 - val_loss: 16.5749 - val_acc: 0.1500\n",
            "Epoch 148/1000\n",
            " - 0s - loss: 9.3114 - acc: 0.1375 - val_loss: 14.1509 - val_acc: 0.1500\n",
            "Epoch 149/1000\n",
            " - 0s - loss: 8.8815 - acc: 0.2250 - val_loss: 11.6751 - val_acc: 0.3000\n",
            "Epoch 150/1000\n",
            " - 0s - loss: 8.5431 - acc: 0.2250 - val_loss: 12.2892 - val_acc: 0.3500\n",
            "Epoch 151/1000\n",
            " - 0s - loss: 8.6433 - acc: 0.1750 - val_loss: 14.4074 - val_acc: 0.1500\n",
            "Epoch 152/1000\n",
            " - 0s - loss: 8.7202 - acc: 0.1750 - val_loss: 15.7683 - val_acc: 0.2000\n",
            "Epoch 153/1000\n",
            " - 0s - loss: 8.5470 - acc: 0.2125 - val_loss: 10.4793 - val_acc: 0.3000\n",
            "Epoch 154/1000\n",
            " - 0s - loss: 9.0551 - acc: 0.2375 - val_loss: 10.8670 - val_acc: 0.2500\n",
            "Epoch 155/1000\n",
            " - 0s - loss: 8.5409 - acc: 0.2000 - val_loss: 13.1598 - val_acc: 0.2500\n",
            "Epoch 156/1000\n",
            " - 0s - loss: 8.3973 - acc: 0.2125 - val_loss: 11.5672 - val_acc: 0.2500\n",
            "Epoch 157/1000\n",
            " - 0s - loss: 8.2744 - acc: 0.2000 - val_loss: 11.1241 - val_acc: 0.3000\n",
            "Epoch 158/1000\n",
            " - 0s - loss: 8.3336 - acc: 0.1500 - val_loss: 13.1210 - val_acc: 0.3000\n",
            "Epoch 159/1000\n",
            " - 0s - loss: 8.2817 - acc: 0.2500 - val_loss: 12.5363 - val_acc: 0.3000\n",
            "Epoch 160/1000\n",
            " - 0s - loss: 8.1978 - acc: 0.2125 - val_loss: 12.6099 - val_acc: 0.3000\n",
            "Epoch 161/1000\n",
            " - 0s - loss: 8.3099 - acc: 0.2125 - val_loss: 10.6510 - val_acc: 0.3000\n",
            "Epoch 162/1000\n",
            " - 0s - loss: 7.9254 - acc: 0.2500 - val_loss: 14.7521 - val_acc: 0.2000\n",
            "Epoch 163/1000\n",
            " - 0s - loss: 8.1667 - acc: 0.2375 - val_loss: 10.2397 - val_acc: 0.3000\n",
            "Epoch 164/1000\n",
            " - 0s - loss: 7.9814 - acc: 0.2125 - val_loss: 13.9713 - val_acc: 0.2500\n",
            "Epoch 165/1000\n",
            " - 0s - loss: 8.9257 - acc: 0.1875 - val_loss: 24.8401 - val_acc: 0.2000\n",
            "Epoch 166/1000\n",
            " - 0s - loss: 8.5568 - acc: 0.1625 - val_loss: 13.9198 - val_acc: 0.2500\n",
            "Epoch 167/1000\n",
            " - 0s - loss: 8.1317 - acc: 0.2000 - val_loss: 11.5577 - val_acc: 0.3500\n",
            "Epoch 168/1000\n",
            " - 0s - loss: 8.0060 - acc: 0.2750 - val_loss: 11.7135 - val_acc: 0.2500\n",
            "Epoch 169/1000\n",
            " - 0s - loss: 7.9060 - acc: 0.2750 - val_loss: 12.2560 - val_acc: 0.3000\n",
            "Epoch 170/1000\n",
            " - 0s - loss: 7.8065 - acc: 0.2250 - val_loss: 12.9514 - val_acc: 0.2000\n",
            "Epoch 171/1000\n",
            " - 0s - loss: 7.9005 - acc: 0.2500 - val_loss: 10.9406 - val_acc: 0.3000\n",
            "Epoch 172/1000\n",
            " - 0s - loss: 8.2818 - acc: 0.1625 - val_loss: 13.7073 - val_acc: 0.2000\n",
            "Epoch 173/1000\n",
            " - 0s - loss: 8.1730 - acc: 0.2125 - val_loss: 10.6252 - val_acc: 0.3000\n",
            "Epoch 174/1000\n",
            " - 0s - loss: 7.9366 - acc: 0.1875 - val_loss: 10.4239 - val_acc: 0.3000\n",
            "Epoch 175/1000\n",
            " - 0s - loss: 8.0233 - acc: 0.2250 - val_loss: 12.1418 - val_acc: 0.3000\n",
            "Epoch 176/1000\n",
            " - 0s - loss: 7.9081 - acc: 0.2125 - val_loss: 12.2876 - val_acc: 0.2500\n",
            "Epoch 177/1000\n",
            " - 0s - loss: 7.7861 - acc: 0.2500 - val_loss: 11.7599 - val_acc: 0.3000\n",
            "Epoch 178/1000\n",
            " - 0s - loss: 7.9486 - acc: 0.2250 - val_loss: 14.1385 - val_acc: 0.2500\n",
            "Epoch 179/1000\n",
            " - 0s - loss: 7.9228 - acc: 0.1875 - val_loss: 14.5946 - val_acc: 0.2000\n",
            "Epoch 180/1000\n",
            " - 0s - loss: 7.7491 - acc: 0.2375 - val_loss: 12.8885 - val_acc: 0.2000\n",
            "Epoch 181/1000\n",
            " - 0s - loss: 7.7207 - acc: 0.1750 - val_loss: 15.0017 - val_acc: 0.2000\n",
            "Epoch 182/1000\n",
            " - 0s - loss: 7.9923 - acc: 0.2875 - val_loss: 9.8020 - val_acc: 0.2000\n",
            "Epoch 183/1000\n",
            " - 0s - loss: 7.7827 - acc: 0.2250 - val_loss: 14.4868 - val_acc: 0.2000\n",
            "Epoch 184/1000\n",
            " - 0s - loss: 7.6223 - acc: 0.2250 - val_loss: 13.0385 - val_acc: 0.2500\n",
            "Epoch 185/1000\n",
            " - 0s - loss: 7.9453 - acc: 0.2500 - val_loss: 12.8632 - val_acc: 0.2500\n",
            "Epoch 186/1000\n",
            " - 0s - loss: 7.7187 - acc: 0.2125 - val_loss: 14.6592 - val_acc: 0.2000\n",
            "Epoch 187/1000\n",
            " - 0s - loss: 7.7779 - acc: 0.2250 - val_loss: 14.4853 - val_acc: 0.2000\n",
            "Epoch 188/1000\n",
            " - 0s - loss: 7.8036 - acc: 0.2500 - val_loss: 11.7746 - val_acc: 0.2500\n",
            "Epoch 189/1000\n",
            " - 0s - loss: 7.6232 - acc: 0.2500 - val_loss: 10.4015 - val_acc: 0.3500\n",
            "Epoch 190/1000\n",
            " - 0s - loss: 7.8988 - acc: 0.1750 - val_loss: 13.6523 - val_acc: 0.2500\n",
            "Epoch 191/1000\n",
            " - 0s - loss: 7.6505 - acc: 0.2875 - val_loss: 13.6588 - val_acc: 0.2000\n",
            "Epoch 192/1000\n",
            " - 0s - loss: 7.7816 - acc: 0.2000 - val_loss: 15.4066 - val_acc: 0.2000\n",
            "Epoch 193/1000\n",
            " - 0s - loss: 7.8347 - acc: 0.2500 - val_loss: 14.5248 - val_acc: 0.2000\n",
            "Epoch 194/1000\n",
            " - 0s - loss: 7.5774 - acc: 0.2500 - val_loss: 14.4507 - val_acc: 0.2500\n",
            "Epoch 195/1000\n",
            " - 0s - loss: 7.7764 - acc: 0.2250 - val_loss: 14.0007 - val_acc: 0.2500\n",
            "Epoch 196/1000\n",
            " - 0s - loss: 7.6148 - acc: 0.2500 - val_loss: 11.2324 - val_acc: 0.2000\n",
            "Epoch 197/1000\n",
            " - 0s - loss: 7.9813 - acc: 0.2250 - val_loss: 12.1805 - val_acc: 0.2500\n",
            "Epoch 198/1000\n",
            " - 0s - loss: 7.5508 - acc: 0.2000 - val_loss: 13.9388 - val_acc: 0.2000\n",
            "Epoch 199/1000\n",
            " - 0s - loss: 7.7126 - acc: 0.2250 - val_loss: 11.7075 - val_acc: 0.2000\n",
            "Epoch 200/1000\n",
            " - 0s - loss: 7.6067 - acc: 0.2250 - val_loss: 12.7859 - val_acc: 0.2500\n",
            "Epoch 201/1000\n",
            " - 0s - loss: 7.4145 - acc: 0.2750 - val_loss: 11.1381 - val_acc: 0.2500\n",
            "Epoch 202/1000\n",
            " - 0s - loss: 7.5237 - acc: 0.2125 - val_loss: 16.1670 - val_acc: 0.2500\n",
            "Epoch 203/1000\n",
            " - 0s - loss: 7.8921 - acc: 0.1750 - val_loss: 9.8325 - val_acc: 0.3000\n",
            "Epoch 204/1000\n",
            " - 0s - loss: 7.4065 - acc: 0.2750 - val_loss: 12.6564 - val_acc: 0.3000\n",
            "Epoch 205/1000\n",
            " - 0s - loss: 7.3926 - acc: 0.3000 - val_loss: 16.1304 - val_acc: 0.1500\n",
            "Epoch 206/1000\n",
            " - 0s - loss: 7.6444 - acc: 0.2625 - val_loss: 10.6775 - val_acc: 0.2000\n",
            "Epoch 207/1000\n",
            " - 0s - loss: 7.5888 - acc: 0.2625 - val_loss: 11.3752 - val_acc: 0.2000\n",
            "Epoch 208/1000\n",
            " - 0s - loss: 7.4527 - acc: 0.2750 - val_loss: 13.8253 - val_acc: 0.2500\n",
            "Epoch 209/1000\n",
            " - 0s - loss: 7.6034 - acc: 0.2250 - val_loss: 13.1254 - val_acc: 0.2000\n",
            "Epoch 210/1000\n",
            " - 0s - loss: 7.7948 - acc: 0.1750 - val_loss: 11.6543 - val_acc: 0.2000\n",
            "Epoch 211/1000\n",
            " - 0s - loss: 7.9809 - acc: 0.2125 - val_loss: 14.1135 - val_acc: 0.2500\n",
            "Epoch 212/1000\n",
            " - 0s - loss: 7.7215 - acc: 0.2625 - val_loss: 13.5803 - val_acc: 0.2500\n",
            "Epoch 213/1000\n",
            " - 0s - loss: 7.3707 - acc: 0.2750 - val_loss: 11.4080 - val_acc: 0.2500\n",
            "Epoch 214/1000\n",
            " - 0s - loss: 7.6866 - acc: 0.2000 - val_loss: 12.0342 - val_acc: 0.2000\n",
            "Epoch 215/1000\n",
            " - 0s - loss: 7.4164 - acc: 0.2375 - val_loss: 15.5780 - val_acc: 0.2000\n",
            "Epoch 216/1000\n",
            " - 0s - loss: 7.4156 - acc: 0.1750 - val_loss: 11.6442 - val_acc: 0.2500\n",
            "Epoch 217/1000\n",
            " - 0s - loss: 7.7147 - acc: 0.2375 - val_loss: 12.3315 - val_acc: 0.2000\n",
            "Epoch 218/1000\n",
            " - 0s - loss: 7.6702 - acc: 0.2875 - val_loss: 14.6096 - val_acc: 0.2000\n",
            "Epoch 219/1000\n",
            " - 0s - loss: 7.5529 - acc: 0.2250 - val_loss: 11.7502 - val_acc: 0.2000\n",
            "Epoch 220/1000\n",
            " - 0s - loss: 7.7285 - acc: 0.2000 - val_loss: 16.3030 - val_acc: 0.2000\n",
            "Epoch 221/1000\n",
            " - 0s - loss: 7.6380 - acc: 0.2000 - val_loss: 11.8475 - val_acc: 0.1500\n",
            "Epoch 222/1000\n",
            " - 0s - loss: 7.7690 - acc: 0.2000 - val_loss: 16.2967 - val_acc: 0.1500\n",
            "Epoch 223/1000\n",
            " - 0s - loss: 7.3844 - acc: 0.2250 - val_loss: 11.5440 - val_acc: 0.2000\n",
            "Epoch 224/1000\n",
            " - 0s - loss: 7.5441 - acc: 0.2375 - val_loss: 12.8088 - val_acc: 0.1500\n",
            "Epoch 225/1000\n",
            " - 0s - loss: 7.7616 - acc: 0.2375 - val_loss: 11.7214 - val_acc: 0.1500\n",
            "Epoch 226/1000\n",
            " - 0s - loss: 7.5764 - acc: 0.2625 - val_loss: 12.4324 - val_acc: 0.1500\n",
            "Epoch 227/1000\n",
            " - 0s - loss: 7.4422 - acc: 0.2625 - val_loss: 12.2734 - val_acc: 0.1500\n",
            "Epoch 228/1000\n",
            " - 0s - loss: 7.4076 - acc: 0.2250 - val_loss: 13.4228 - val_acc: 0.2500\n",
            "Epoch 229/1000\n",
            " - 0s - loss: 7.5137 - acc: 0.2625 - val_loss: 13.2670 - val_acc: 0.2500\n",
            "Epoch 230/1000\n",
            " - 0s - loss: 7.4659 - acc: 0.1750 - val_loss: 15.8183 - val_acc: 0.2000\n",
            "Epoch 231/1000\n",
            " - 0s - loss: 7.6137 - acc: 0.2625 - val_loss: 14.0119 - val_acc: 0.2500\n",
            "Epoch 232/1000\n",
            " - 0s - loss: 7.4556 - acc: 0.3125 - val_loss: 13.3628 - val_acc: 0.2500\n",
            "Epoch 233/1000\n",
            " - 0s - loss: 7.5295 - acc: 0.2375 - val_loss: 11.7138 - val_acc: 0.1500\n",
            "Epoch 234/1000\n",
            " - 0s - loss: 7.4153 - acc: 0.2625 - val_loss: 11.6003 - val_acc: 0.2000\n",
            "Epoch 235/1000\n",
            " - 0s - loss: 7.4285 - acc: 0.2125 - val_loss: 14.7597 - val_acc: 0.2000\n",
            "Epoch 236/1000\n",
            " - 0s - loss: 7.4186 - acc: 0.3000 - val_loss: 12.5808 - val_acc: 0.2000\n",
            "Epoch 237/1000\n",
            " - 0s - loss: 7.5138 - acc: 0.2625 - val_loss: 11.8268 - val_acc: 0.2000\n",
            "Epoch 238/1000\n",
            " - 0s - loss: 7.5833 - acc: 0.2375 - val_loss: 12.7269 - val_acc: 0.1500\n",
            "Epoch 239/1000\n",
            " - 0s - loss: 7.5457 - acc: 0.2625 - val_loss: 14.4095 - val_acc: 0.2500\n",
            "Epoch 240/1000\n",
            " - 0s - loss: 7.5174 - acc: 0.2625 - val_loss: 13.0946 - val_acc: 0.2500\n",
            "Epoch 241/1000\n",
            " - 0s - loss: 7.5275 - acc: 0.2500 - val_loss: 15.5599 - val_acc: 0.2500\n",
            "Epoch 242/1000\n",
            " - 0s - loss: 7.6350 - acc: 0.2375 - val_loss: 14.3936 - val_acc: 0.2500\n",
            "Epoch 243/1000\n",
            " - 0s - loss: 7.3966 - acc: 0.2375 - val_loss: 11.4972 - val_acc: 0.3000\n",
            "Epoch 244/1000\n",
            " - 0s - loss: 7.4871 - acc: 0.2500 - val_loss: 13.6814 - val_acc: 0.2500\n",
            "Epoch 245/1000\n",
            " - 0s - loss: 7.3846 - acc: 0.2500 - val_loss: 12.8890 - val_acc: 0.1500\n",
            "Epoch 246/1000\n",
            " - 0s - loss: 7.4168 - acc: 0.2875 - val_loss: 11.7124 - val_acc: 0.3000\n",
            "Epoch 247/1000\n",
            " - 0s - loss: 7.6446 - acc: 0.2250 - val_loss: 16.2914 - val_acc: 0.2000\n",
            "Epoch 248/1000\n",
            " - 0s - loss: 7.5414 - acc: 0.1750 - val_loss: 18.9212 - val_acc: 0.2000\n",
            "Epoch 249/1000\n",
            " - 0s - loss: 7.6408 - acc: 0.2750 - val_loss: 12.1631 - val_acc: 0.1500\n",
            "Epoch 250/1000\n",
            " - 0s - loss: 7.4441 - acc: 0.2000 - val_loss: 14.0208 - val_acc: 0.2500\n",
            "Epoch 251/1000\n",
            " - 0s - loss: 7.3832 - acc: 0.2125 - val_loss: 15.8605 - val_acc: 0.2000\n",
            "Epoch 252/1000\n",
            " - 0s - loss: 7.5236 - acc: 0.2875 - val_loss: 11.6969 - val_acc: 0.1500\n",
            "Epoch 253/1000\n",
            " - 0s - loss: 7.6423 - acc: 0.2250 - val_loss: 13.8911 - val_acc: 0.2500\n",
            "Epoch 254/1000\n",
            " - 0s - loss: 7.7799 - acc: 0.2375 - val_loss: 13.3981 - val_acc: 0.2500\n",
            "Epoch 255/1000\n",
            " - 0s - loss: 7.3602 - acc: 0.2625 - val_loss: 13.0924 - val_acc: 0.1500\n",
            "Epoch 256/1000\n",
            " - 0s - loss: 7.4163 - acc: 0.2250 - val_loss: 14.1100 - val_acc: 0.2000\n",
            "Epoch 257/1000\n",
            " - 0s - loss: 7.4532 - acc: 0.3000 - val_loss: 12.2001 - val_acc: 0.1500\n",
            "Epoch 258/1000\n",
            " - 0s - loss: 7.5495 - acc: 0.2750 - val_loss: 11.9536 - val_acc: 0.2000\n",
            "Epoch 259/1000\n",
            " - 0s - loss: 7.4296 - acc: 0.2375 - val_loss: 10.6434 - val_acc: 0.3500\n",
            "Epoch 260/1000\n",
            " - 0s - loss: 7.7464 - acc: 0.2250 - val_loss: 13.6332 - val_acc: 0.1500\n",
            "Epoch 261/1000\n",
            " - 0s - loss: 7.3552 - acc: 0.2875 - val_loss: 12.1647 - val_acc: 0.1500\n",
            "Epoch 262/1000\n",
            " - 0s - loss: 7.3613 - acc: 0.2625 - val_loss: 13.0733 - val_acc: 0.2000\n",
            "Epoch 263/1000\n",
            " - 0s - loss: 7.3759 - acc: 0.2625 - val_loss: 13.9766 - val_acc: 0.2500\n",
            "Epoch 264/1000\n",
            " - 0s - loss: 7.4185 - acc: 0.2375 - val_loss: 16.3022 - val_acc: 0.2000\n",
            "Epoch 265/1000\n",
            " - 0s - loss: 7.8771 - acc: 0.2375 - val_loss: 12.0627 - val_acc: 0.1500\n",
            "Epoch 266/1000\n",
            " - 0s - loss: 7.4877 - acc: 0.2500 - val_loss: 10.4798 - val_acc: 0.2500\n",
            "Epoch 267/1000\n",
            " - 0s - loss: 7.4555 - acc: 0.2750 - val_loss: 12.7040 - val_acc: 0.1500\n",
            "Epoch 268/1000\n",
            " - 0s - loss: 7.5280 - acc: 0.3250 - val_loss: 14.0364 - val_acc: 0.2500\n",
            "Epoch 269/1000\n",
            " - 0s - loss: 7.3669 - acc: 0.2500 - val_loss: 12.3889 - val_acc: 0.2000\n",
            "Epoch 270/1000\n",
            " - 0s - loss: 7.5956 - acc: 0.1875 - val_loss: 12.5177 - val_acc: 0.3000\n",
            "Epoch 271/1000\n",
            " - 0s - loss: 7.1444 - acc: 0.2125 - val_loss: 16.4793 - val_acc: 0.2500\n",
            "Epoch 272/1000\n",
            " - 0s - loss: 7.5538 - acc: 0.2125 - val_loss: 13.6116 - val_acc: 0.2000\n",
            "Epoch 273/1000\n",
            " - 0s - loss: 7.7575 - acc: 0.3000 - val_loss: 14.0941 - val_acc: 0.2500\n",
            "Epoch 274/1000\n",
            " - 0s - loss: 7.4482 - acc: 0.3000 - val_loss: 13.2420 - val_acc: 0.2500\n",
            "Epoch 275/1000\n",
            " - 0s - loss: 7.5381 - acc: 0.2875 - val_loss: 11.0075 - val_acc: 0.2500\n",
            "Epoch 276/1000\n",
            " - 0s - loss: 7.5664 - acc: 0.2125 - val_loss: 13.0093 - val_acc: 0.1500\n",
            "Epoch 277/1000\n",
            " - 0s - loss: 7.3648 - acc: 0.2375 - val_loss: 12.3176 - val_acc: 0.1500\n",
            "Epoch 278/1000\n",
            " - 0s - loss: 7.3726 - acc: 0.2500 - val_loss: 12.4672 - val_acc: 0.2000\n",
            "Epoch 279/1000\n",
            " - 0s - loss: 7.5817 - acc: 0.2750 - val_loss: 12.1501 - val_acc: 0.2000\n",
            "Epoch 280/1000\n",
            " - 0s - loss: 7.5077 - acc: 0.2125 - val_loss: 11.5862 - val_acc: 0.2000\n",
            "Epoch 281/1000\n",
            " - 0s - loss: 7.3045 - acc: 0.2250 - val_loss: 15.1959 - val_acc: 0.2500\n",
            "Epoch 282/1000\n",
            " - 0s - loss: 7.7406 - acc: 0.2875 - val_loss: 11.9713 - val_acc: 0.1500\n",
            "Epoch 283/1000\n",
            " - 0s - loss: 7.2909 - acc: 0.2625 - val_loss: 14.9276 - val_acc: 0.2500\n",
            "Epoch 284/1000\n",
            " - 0s - loss: 7.4449 - acc: 0.2000 - val_loss: 15.1461 - val_acc: 0.2500\n",
            "Epoch 285/1000\n",
            " - 0s - loss: 7.4340 - acc: 0.2875 - val_loss: 12.8806 - val_acc: 0.2000\n",
            "Epoch 286/1000\n",
            " - 0s - loss: 7.3908 - acc: 0.2250 - val_loss: 12.7862 - val_acc: 0.2500\n",
            "Epoch 287/1000\n",
            " - 0s - loss: 7.3785 - acc: 0.2375 - val_loss: 13.3710 - val_acc: 0.2000\n",
            "Epoch 288/1000\n",
            " - 0s - loss: 7.3943 - acc: 0.2500 - val_loss: 13.7118 - val_acc: 0.2500\n",
            "Epoch 289/1000\n",
            " - 0s - loss: 7.5532 - acc: 0.1625 - val_loss: 11.9463 - val_acc: 0.2000\n",
            "Epoch 290/1000\n",
            " - 0s - loss: 7.4056 - acc: 0.2500 - val_loss: 10.9255 - val_acc: 0.2500\n",
            "Epoch 291/1000\n",
            " - 0s - loss: 7.4534 - acc: 0.2000 - val_loss: 13.7400 - val_acc: 0.2000\n",
            "Epoch 292/1000\n",
            " - 0s - loss: 7.4402 - acc: 0.2375 - val_loss: 13.7103 - val_acc: 0.1500\n",
            "Epoch 293/1000\n",
            " - 0s - loss: 7.3997 - acc: 0.2875 - val_loss: 12.1728 - val_acc: 0.1500\n",
            "Epoch 294/1000\n",
            " - 0s - loss: 7.3647 - acc: 0.2500 - val_loss: 12.5188 - val_acc: 0.1500\n",
            "Epoch 295/1000\n",
            " - 0s - loss: 7.5217 - acc: 0.2750 - val_loss: 13.3850 - val_acc: 0.1500\n",
            "Epoch 296/1000\n",
            " - 0s - loss: 7.3379 - acc: 0.2875 - val_loss: 14.0928 - val_acc: 0.2500\n",
            "Epoch 297/1000\n",
            " - 0s - loss: 7.3232 - acc: 0.2750 - val_loss: 14.9609 - val_acc: 0.2500\n",
            "Epoch 298/1000\n",
            " - 0s - loss: 7.3839 - acc: 0.2625 - val_loss: 11.5864 - val_acc: 0.2000\n",
            "Epoch 299/1000\n",
            " - 0s - loss: 7.2669 - acc: 0.2625 - val_loss: 13.2421 - val_acc: 0.2000\n",
            "Epoch 300/1000\n",
            " - 0s - loss: 7.4967 - acc: 0.3250 - val_loss: 12.8555 - val_acc: 0.1500\n",
            "Epoch 301/1000\n",
            " - 0s - loss: 7.4901 - acc: 0.2375 - val_loss: 12.0189 - val_acc: 0.2500\n",
            "Epoch 302/1000\n",
            " - 0s - loss: 7.1915 - acc: 0.2625 - val_loss: 11.7529 - val_acc: 0.2500\n",
            "Epoch 303/1000\n",
            " - 0s - loss: 7.3319 - acc: 0.2000 - val_loss: 14.4012 - val_acc: 0.2500\n",
            "Epoch 304/1000\n",
            " - 0s - loss: 7.2196 - acc: 0.2500 - val_loss: 14.1119 - val_acc: 0.2500\n",
            "Epoch 305/1000\n",
            " - 0s - loss: 7.5328 - acc: 0.2875 - val_loss: 13.6399 - val_acc: 0.2500\n",
            "Epoch 306/1000\n",
            " - 0s - loss: 7.2780 - acc: 0.2625 - val_loss: 13.6981 - val_acc: 0.2000\n",
            "Epoch 307/1000\n",
            " - 0s - loss: 7.3379 - acc: 0.3000 - val_loss: 12.4251 - val_acc: 0.1500\n",
            "Epoch 308/1000\n",
            " - 0s - loss: 7.3159 - acc: 0.2625 - val_loss: 12.5699 - val_acc: 0.1500\n",
            "Epoch 309/1000\n",
            " - 0s - loss: 7.3998 - acc: 0.2250 - val_loss: 12.6767 - val_acc: 0.1500\n",
            "Epoch 310/1000\n",
            " - 0s - loss: 7.4381 - acc: 0.2500 - val_loss: 13.7402 - val_acc: 0.2000\n",
            "Epoch 311/1000\n",
            " - 0s - loss: 7.2415 - acc: 0.3000 - val_loss: 15.8677 - val_acc: 0.2500\n",
            "Epoch 312/1000\n",
            " - 0s - loss: 7.9785 - acc: 0.2000 - val_loss: 17.4159 - val_acc: 0.2000\n",
            "Epoch 313/1000\n",
            " - 0s - loss: 7.3781 - acc: 0.2250 - val_loss: 15.5107 - val_acc: 0.2500\n",
            "Epoch 314/1000\n",
            " - 0s - loss: 7.5746 - acc: 0.2250 - val_loss: 14.9464 - val_acc: 0.2500\n",
            "Epoch 315/1000\n",
            " - 0s - loss: 7.3094 - acc: 0.3000 - val_loss: 14.6698 - val_acc: 0.2500\n",
            "Epoch 316/1000\n",
            " - 0s - loss: 7.1824 - acc: 0.3000 - val_loss: 11.8046 - val_acc: 0.1500\n",
            "Epoch 317/1000\n",
            " - 0s - loss: 7.3641 - acc: 0.2625 - val_loss: 11.7588 - val_acc: 0.2000\n",
            "Epoch 318/1000\n",
            " - 0s - loss: 7.5020 - acc: 0.2250 - val_loss: 15.4968 - val_acc: 0.2500\n",
            "Epoch 319/1000\n",
            " - 0s - loss: 7.4816 - acc: 0.2875 - val_loss: 16.5529 - val_acc: 0.2000\n",
            "Epoch 320/1000\n",
            " - 0s - loss: 7.4355 - acc: 0.2500 - val_loss: 11.3998 - val_acc: 0.2500\n",
            "Epoch 321/1000\n",
            " - 0s - loss: 7.6262 - acc: 0.2375 - val_loss: 13.4196 - val_acc: 0.2000\n",
            "Epoch 322/1000\n",
            " - 0s - loss: 7.4720 - acc: 0.1875 - val_loss: 11.8041 - val_acc: 0.2500\n",
            "Epoch 323/1000\n",
            " - 0s - loss: 7.4140 - acc: 0.1875 - val_loss: 14.1924 - val_acc: 0.2500\n",
            "Epoch 324/1000\n",
            " - 0s - loss: 7.4024 - acc: 0.1875 - val_loss: 14.3460 - val_acc: 0.2000\n",
            "Epoch 325/1000\n",
            " - 0s - loss: 7.4022 - acc: 0.2375 - val_loss: 12.9271 - val_acc: 0.2000\n",
            "Epoch 326/1000\n",
            " - 0s - loss: 7.1072 - acc: 0.3000 - val_loss: 11.1500 - val_acc: 0.2500\n",
            "Epoch 327/1000\n",
            " - 0s - loss: 7.3381 - acc: 0.2750 - val_loss: 14.2162 - val_acc: 0.2500\n",
            "Epoch 328/1000\n",
            " - 0s - loss: 7.2972 - acc: 0.3250 - val_loss: 10.9723 - val_acc: 0.2000\n",
            "Epoch 329/1000\n",
            " - 0s - loss: 7.1891 - acc: 0.3125 - val_loss: 11.2021 - val_acc: 0.2500\n",
            "Epoch 330/1000\n",
            " - 0s - loss: 7.9134 - acc: 0.2000 - val_loss: 15.0773 - val_acc: 0.2000\n",
            "Epoch 331/1000\n",
            " - 0s - loss: 7.2908 - acc: 0.2625 - val_loss: 15.0440 - val_acc: 0.2500\n",
            "Epoch 332/1000\n",
            " - 0s - loss: 7.4001 - acc: 0.2375 - val_loss: 13.1142 - val_acc: 0.1500\n",
            "Epoch 333/1000\n",
            " - 0s - loss: 7.1001 - acc: 0.2750 - val_loss: 11.4633 - val_acc: 0.2500\n",
            "Epoch 334/1000\n",
            " - 0s - loss: 7.2677 - acc: 0.2625 - val_loss: 13.5385 - val_acc: 0.2000\n",
            "Epoch 335/1000\n",
            " - 0s - loss: 7.1167 - acc: 0.2625 - val_loss: 11.2447 - val_acc: 0.2500\n",
            "Epoch 336/1000\n",
            " - 0s - loss: 7.4137 - acc: 0.2000 - val_loss: 12.2762 - val_acc: 0.1500\n",
            "Epoch 337/1000\n",
            " - 0s - loss: 7.4835 - acc: 0.2500 - val_loss: 11.5582 - val_acc: 0.2000\n",
            "Epoch 338/1000\n",
            " - 0s - loss: 7.4054 - acc: 0.2000 - val_loss: 12.7775 - val_acc: 0.1500\n",
            "Epoch 339/1000\n",
            " - 0s - loss: 7.1738 - acc: 0.2750 - val_loss: 12.1284 - val_acc: 0.2500\n",
            "Epoch 340/1000\n",
            " - 0s - loss: 7.4065 - acc: 0.2125 - val_loss: 13.5928 - val_acc: 0.2000\n",
            "Epoch 341/1000\n",
            " - 0s - loss: 7.1800 - acc: 0.2625 - val_loss: 15.8773 - val_acc: 0.2500\n",
            "Epoch 342/1000\n",
            " - 0s - loss: 7.2623 - acc: 0.2875 - val_loss: 11.1642 - val_acc: 0.2500\n",
            "Epoch 343/1000\n",
            " - 0s - loss: 7.0866 - acc: 0.2625 - val_loss: 16.3038 - val_acc: 0.2000\n",
            "Epoch 344/1000\n",
            " - 0s - loss: 7.2238 - acc: 0.2375 - val_loss: 12.6166 - val_acc: 0.1500\n",
            "Epoch 345/1000\n",
            " - 0s - loss: 7.2917 - acc: 0.3000 - val_loss: 12.2861 - val_acc: 0.1500\n",
            "Epoch 346/1000\n",
            " - 0s - loss: 7.3662 - acc: 0.2875 - val_loss: 14.2388 - val_acc: 0.2500\n",
            "Epoch 347/1000\n",
            " - 0s - loss: 7.1810 - acc: 0.3000 - val_loss: 13.5031 - val_acc: 0.2000\n",
            "Epoch 348/1000\n",
            " - 0s - loss: 7.3082 - acc: 0.2125 - val_loss: 18.3151 - val_acc: 0.2500\n",
            "Epoch 349/1000\n",
            " - 0s - loss: 7.3467 - acc: 0.2875 - val_loss: 12.4422 - val_acc: 0.1500\n",
            "Epoch 350/1000\n",
            " - 0s - loss: 7.2876 - acc: 0.2500 - val_loss: 14.9733 - val_acc: 0.2500\n",
            "Epoch 351/1000\n",
            " - 0s - loss: 7.7676 - acc: 0.2375 - val_loss: 10.4078 - val_acc: 0.3000\n",
            "Epoch 352/1000\n",
            " - 0s - loss: 7.4754 - acc: 0.2625 - val_loss: 12.0554 - val_acc: 0.1500\n",
            "Epoch 353/1000\n",
            " - 0s - loss: 7.2078 - acc: 0.2250 - val_loss: 14.2659 - val_acc: 0.2000\n",
            "Epoch 354/1000\n",
            " - 0s - loss: 7.4659 - acc: 0.2000 - val_loss: 14.8477 - val_acc: 0.2000\n",
            "Epoch 355/1000\n",
            " - 0s - loss: 7.2544 - acc: 0.2750 - val_loss: 12.7756 - val_acc: 0.1500\n",
            "Epoch 356/1000\n",
            " - 0s - loss: 7.0818 - acc: 0.2625 - val_loss: 12.3428 - val_acc: 0.1500\n",
            "Epoch 357/1000\n",
            " - 0s - loss: 7.0825 - acc: 0.2750 - val_loss: 11.6641 - val_acc: 0.2500\n",
            "Epoch 358/1000\n",
            " - 0s - loss: 7.4612 - acc: 0.2000 - val_loss: 14.2056 - val_acc: 0.2500\n",
            "Epoch 359/1000\n",
            " - 0s - loss: 7.1320 - acc: 0.3125 - val_loss: 12.2886 - val_acc: 0.1500\n",
            "Epoch 360/1000\n",
            " - 0s - loss: 7.1739 - acc: 0.1750 - val_loss: 13.4697 - val_acc: 0.2500\n",
            "Epoch 361/1000\n",
            " - 0s - loss: 7.6389 - acc: 0.2750 - val_loss: 11.4551 - val_acc: 0.2000\n",
            "Epoch 362/1000\n",
            " - 0s - loss: 7.2391 - acc: 0.2750 - val_loss: 11.7736 - val_acc: 0.1500\n",
            "Epoch 363/1000\n",
            " - 0s - loss: 7.2121 - acc: 0.2375 - val_loss: 13.3327 - val_acc: 0.2000\n",
            "Epoch 364/1000\n",
            " - 0s - loss: 7.2715 - acc: 0.2750 - val_loss: 14.6169 - val_acc: 0.2000\n",
            "Epoch 365/1000\n",
            " - 0s - loss: 7.8337 - acc: 0.2625 - val_loss: 11.9955 - val_acc: 0.1500\n",
            "Epoch 366/1000\n",
            " - 0s - loss: 7.8979 - acc: 0.2250 - val_loss: 12.4624 - val_acc: 0.1500\n",
            "Epoch 367/1000\n",
            " - 0s - loss: 7.0364 - acc: 0.2375 - val_loss: 15.5025 - val_acc: 0.2500\n",
            "Epoch 368/1000\n",
            " - 0s - loss: 7.2239 - acc: 0.2750 - val_loss: 12.8611 - val_acc: 0.1500\n",
            "Epoch 369/1000\n",
            " - 0s - loss: 7.0190 - acc: 0.3125 - val_loss: 11.3539 - val_acc: 0.2000\n",
            "Epoch 370/1000\n",
            " - 0s - loss: 7.6274 - acc: 0.2625 - val_loss: 13.6434 - val_acc: 0.2000\n",
            "Epoch 371/1000\n",
            " - 0s - loss: 7.1059 - acc: 0.2500 - val_loss: 14.1125 - val_acc: 0.2500\n",
            "Epoch 372/1000\n",
            " - 0s - loss: 7.2272 - acc: 0.2000 - val_loss: 15.0725 - val_acc: 0.2500\n",
            "Epoch 373/1000\n",
            " - 0s - loss: 7.2374 - acc: 0.2750 - val_loss: 13.5882 - val_acc: 0.2000\n",
            "Epoch 374/1000\n",
            " - 0s - loss: 7.1737 - acc: 0.2875 - val_loss: 13.0980 - val_acc: 0.1500\n",
            "Epoch 375/1000\n",
            " - 0s - loss: 7.2392 - acc: 0.2625 - val_loss: 11.0556 - val_acc: 0.2500\n",
            "Epoch 376/1000\n",
            " - 0s - loss: 7.3704 - acc: 0.2250 - val_loss: 14.2801 - val_acc: 0.2000\n",
            "Epoch 377/1000\n",
            " - 0s - loss: 7.1505 - acc: 0.2500 - val_loss: 13.0921 - val_acc: 0.2000\n",
            "Epoch 378/1000\n",
            " - 0s - loss: 7.3667 - acc: 0.2875 - val_loss: 12.4672 - val_acc: 0.1500\n",
            "Epoch 379/1000\n",
            " - 0s - loss: 7.1453 - acc: 0.2625 - val_loss: 12.6122 - val_acc: 0.2000\n",
            "Epoch 380/1000\n",
            " - 0s - loss: 7.1272 - acc: 0.2250 - val_loss: 14.1315 - val_acc: 0.2500\n",
            "Epoch 381/1000\n",
            " - 0s - loss: 7.1569 - acc: 0.2625 - val_loss: 13.0234 - val_acc: 0.2000\n",
            "Epoch 382/1000\n",
            " - 0s - loss: 7.2506 - acc: 0.2625 - val_loss: 12.3770 - val_acc: 0.1500\n",
            "Epoch 383/1000\n",
            " - 0s - loss: 7.2144 - acc: 0.2500 - val_loss: 9.9534 - val_acc: 0.3500\n",
            "Epoch 384/1000\n",
            " - 0s - loss: 7.3984 - acc: 0.2250 - val_loss: 13.7931 - val_acc: 0.2500\n",
            "Epoch 385/1000\n",
            " - 0s - loss: 7.3832 - acc: 0.2125 - val_loss: 12.4719 - val_acc: 0.2500\n",
            "Epoch 386/1000\n",
            " - 0s - loss: 7.1408 - acc: 0.2875 - val_loss: 12.2904 - val_acc: 0.1500\n",
            "Epoch 387/1000\n",
            " - 0s - loss: 7.1610 - acc: 0.2500 - val_loss: 12.3679 - val_acc: 0.1500\n",
            "Epoch 388/1000\n",
            " - 0s - loss: 7.1571 - acc: 0.1875 - val_loss: 14.8048 - val_acc: 0.2500\n",
            "Epoch 389/1000\n",
            " - 0s - loss: 7.3387 - acc: 0.2500 - val_loss: 13.3189 - val_acc: 0.2500\n",
            "Epoch 390/1000\n",
            " - 0s - loss: 7.2976 - acc: 0.1625 - val_loss: 14.8466 - val_acc: 0.2500\n",
            "Epoch 391/1000\n",
            " - 0s - loss: 7.1020 - acc: 0.2750 - val_loss: 11.3779 - val_acc: 0.2500\n",
            "Epoch 392/1000\n",
            " - 0s - loss: 7.2494 - acc: 0.2375 - val_loss: 12.5324 - val_acc: 0.1500\n",
            "Epoch 393/1000\n",
            " - 0s - loss: 7.1477 - acc: 0.2625 - val_loss: 11.3267 - val_acc: 0.2500\n",
            "Epoch 394/1000\n",
            " - 0s - loss: 7.1405 - acc: 0.2250 - val_loss: 10.6333 - val_acc: 0.2500\n",
            "Epoch 395/1000\n",
            " - 0s - loss: 7.8509 - acc: 0.2125 - val_loss: 11.4527 - val_acc: 0.2500\n",
            "Epoch 396/1000\n",
            " - 0s - loss: 7.1950 - acc: 0.2750 - val_loss: 13.7890 - val_acc: 0.2500\n",
            "Epoch 397/1000\n",
            " - 0s - loss: 7.2968 - acc: 0.3125 - val_loss: 13.2439 - val_acc: 0.2500\n",
            "Epoch 398/1000\n",
            " - 0s - loss: 7.0805 - acc: 0.2750 - val_loss: 11.7987 - val_acc: 0.2000\n",
            "Epoch 399/1000\n",
            " - 0s - loss: 7.1718 - acc: 0.2625 - val_loss: 14.9526 - val_acc: 0.2500\n",
            "Epoch 400/1000\n",
            " - 0s - loss: 7.4637 - acc: 0.2375 - val_loss: 11.3043 - val_acc: 0.2500\n",
            "Epoch 401/1000\n",
            " - 0s - loss: 7.2879 - acc: 0.2250 - val_loss: 15.5767 - val_acc: 0.2500\n",
            "Epoch 402/1000\n",
            " - 0s - loss: 7.4726 - acc: 0.2500 - val_loss: 11.4903 - val_acc: 0.2500\n",
            "Epoch 403/1000\n",
            " - 0s - loss: 7.2487 - acc: 0.2375 - val_loss: 13.5312 - val_acc: 0.2000\n",
            "Epoch 404/1000\n",
            " - 0s - loss: 7.1189 - acc: 0.2375 - val_loss: 11.6417 - val_acc: 0.2500\n",
            "Epoch 405/1000\n",
            " - 0s - loss: 7.0542 - acc: 0.2625 - val_loss: 14.6047 - val_acc: 0.2500\n",
            "Epoch 406/1000\n",
            " - 0s - loss: 7.5029 - acc: 0.1750 - val_loss: 17.4913 - val_acc: 0.2500\n",
            "Epoch 407/1000\n",
            " - 0s - loss: 7.2344 - acc: 0.2625 - val_loss: 10.9619 - val_acc: 0.2500\n",
            "Epoch 408/1000\n",
            " - 0s - loss: 7.6020 - acc: 0.2125 - val_loss: 17.2855 - val_acc: 0.2500\n",
            "Epoch 409/1000\n",
            " - 0s - loss: 7.1635 - acc: 0.2750 - val_loss: 11.5510 - val_acc: 0.2000\n",
            "Epoch 410/1000\n",
            " - 0s - loss: 7.0289 - acc: 0.2375 - val_loss: 13.4732 - val_acc: 0.2500\n",
            "Epoch 411/1000\n",
            " - 0s - loss: 7.1457 - acc: 0.2375 - val_loss: 13.4920 - val_acc: 0.2000\n",
            "Epoch 412/1000\n",
            " - 0s - loss: 7.4754 - acc: 0.2500 - val_loss: 14.5854 - val_acc: 0.2000\n",
            "Epoch 413/1000\n",
            " - 0s - loss: 7.2477 - acc: 0.2250 - val_loss: 13.7693 - val_acc: 0.2000\n",
            "Epoch 414/1000\n",
            " - 0s - loss: 7.1153 - acc: 0.1875 - val_loss: 10.7776 - val_acc: 0.2000\n",
            "Epoch 415/1000\n",
            " - 0s - loss: 7.1872 - acc: 0.2000 - val_loss: 17.2338 - val_acc: 0.2000\n",
            "Epoch 416/1000\n",
            " - 0s - loss: 7.2898 - acc: 0.2500 - val_loss: 12.1373 - val_acc: 0.1500\n",
            "Epoch 417/1000\n",
            " - 0s - loss: 7.2532 - acc: 0.2625 - val_loss: 13.3835 - val_acc: 0.2000\n",
            "Epoch 418/1000\n",
            " - 0s - loss: 7.3005 - acc: 0.2625 - val_loss: 12.5275 - val_acc: 0.2000\n",
            "Epoch 419/1000\n",
            " - 0s - loss: 7.0015 - acc: 0.2750 - val_loss: 12.7936 - val_acc: 0.1500\n",
            "Epoch 420/1000\n",
            " - 0s - loss: 7.0325 - acc: 0.2750 - val_loss: 13.3577 - val_acc: 0.2500\n",
            "Epoch 421/1000\n",
            " - 0s - loss: 7.0068 - acc: 0.2250 - val_loss: 16.1353 - val_acc: 0.2000\n",
            "Epoch 422/1000\n",
            " - 0s - loss: 7.3303 - acc: 0.2500 - val_loss: 14.3540 - val_acc: 0.2500\n",
            "Epoch 423/1000\n",
            " - 0s - loss: 7.2916 - acc: 0.2625 - val_loss: 14.3219 - val_acc: 0.2000\n",
            "Epoch 424/1000\n",
            " - 0s - loss: 7.3993 - acc: 0.2750 - val_loss: 12.5996 - val_acc: 0.2500\n",
            "Epoch 425/1000\n",
            " - 0s - loss: 7.1947 - acc: 0.2625 - val_loss: 12.2167 - val_acc: 0.2000\n",
            "Epoch 426/1000\n",
            " - 0s - loss: 7.1625 - acc: 0.3000 - val_loss: 11.5901 - val_acc: 0.2500\n",
            "Epoch 427/1000\n",
            " - 0s - loss: 7.4244 - acc: 0.2375 - val_loss: 11.9421 - val_acc: 0.2000\n",
            "Epoch 428/1000\n",
            " - 0s - loss: 7.1831 - acc: 0.2250 - val_loss: 12.8740 - val_acc: 0.2500\n",
            "Epoch 429/1000\n",
            " - 0s - loss: 7.1227 - acc: 0.2625 - val_loss: 11.6355 - val_acc: 0.1500\n",
            "Epoch 430/1000\n",
            " - 0s - loss: 7.5604 - acc: 0.2750 - val_loss: 11.8380 - val_acc: 0.3000\n",
            "Epoch 431/1000\n",
            " - 0s - loss: 7.1416 - acc: 0.2625 - val_loss: 10.9612 - val_acc: 0.2000\n",
            "Epoch 432/1000\n",
            " - 0s - loss: 7.0430 - acc: 0.2500 - val_loss: 14.1643 - val_acc: 0.2500\n",
            "Epoch 433/1000\n",
            " - 0s - loss: 6.9088 - acc: 0.2500 - val_loss: 12.3099 - val_acc: 0.1500\n",
            "Epoch 434/1000\n",
            " - 0s - loss: 7.0340 - acc: 0.2750 - val_loss: 13.2190 - val_acc: 0.2000\n",
            "Epoch 435/1000\n",
            " - 0s - loss: 7.1736 - acc: 0.2250 - val_loss: 13.3329 - val_acc: 0.2000\n",
            "Epoch 436/1000\n",
            " - 0s - loss: 7.3628 - acc: 0.2625 - val_loss: 12.4290 - val_acc: 0.1500\n",
            "Epoch 437/1000\n",
            " - 0s - loss: 7.1126 - acc: 0.2875 - val_loss: 13.3774 - val_acc: 0.2000\n",
            "Epoch 438/1000\n",
            " - 0s - loss: 7.1307 - acc: 0.2875 - val_loss: 12.0465 - val_acc: 0.1500\n",
            "Epoch 439/1000\n",
            " - 0s - loss: 7.8201 - acc: 0.1875 - val_loss: 16.3919 - val_acc: 0.2500\n",
            "Epoch 440/1000\n",
            " - 0s - loss: 7.1563 - acc: 0.2375 - val_loss: 14.4191 - val_acc: 0.2500\n",
            "Epoch 441/1000\n",
            " - 0s - loss: 7.1985 - acc: 0.2250 - val_loss: 12.3619 - val_acc: 0.1500\n",
            "Epoch 442/1000\n",
            " - 0s - loss: 7.0667 - acc: 0.2750 - val_loss: 11.3488 - val_acc: 0.1500\n",
            "Epoch 443/1000\n",
            " - 0s - loss: 7.0349 - acc: 0.2500 - val_loss: 12.3314 - val_acc: 0.1500\n",
            "Epoch 444/1000\n",
            " - 0s - loss: 7.0772 - acc: 0.2750 - val_loss: 10.7069 - val_acc: 0.3000\n",
            "Epoch 445/1000\n",
            " - 0s - loss: 6.9323 - acc: 0.2625 - val_loss: 15.9792 - val_acc: 0.2000\n",
            "Epoch 446/1000\n",
            " - 0s - loss: 7.1836 - acc: 0.2375 - val_loss: 16.6877 - val_acc: 0.2000\n",
            "Epoch 447/1000\n",
            " - 0s - loss: 7.2953 - acc: 0.2000 - val_loss: 12.2756 - val_acc: 0.1500\n",
            "Epoch 448/1000\n",
            " - 0s - loss: 7.2795 - acc: 0.2125 - val_loss: 10.8977 - val_acc: 0.2500\n",
            "Epoch 449/1000\n",
            " - 0s - loss: 7.4852 - acc: 0.2000 - val_loss: 11.8927 - val_acc: 0.1500\n",
            "Epoch 450/1000\n",
            " - 0s - loss: 7.2211 - acc: 0.2625 - val_loss: 10.8887 - val_acc: 0.3000\n",
            "Epoch 451/1000\n",
            " - 0s - loss: 7.3291 - acc: 0.2000 - val_loss: 11.1790 - val_acc: 0.3000\n",
            "Epoch 452/1000\n",
            " - 0s - loss: 7.1000 - acc: 0.2750 - val_loss: 12.7622 - val_acc: 0.1500\n",
            "Epoch 453/1000\n",
            " - 0s - loss: 7.0835 - acc: 0.3000 - val_loss: 17.2908 - val_acc: 0.2000\n",
            "Epoch 454/1000\n",
            " - 0s - loss: 7.3937 - acc: 0.2125 - val_loss: 14.8089 - val_acc: 0.2500\n",
            "Epoch 455/1000\n",
            " - 0s - loss: 7.1549 - acc: 0.2375 - val_loss: 14.3279 - val_acc: 0.2500\n",
            "Epoch 456/1000\n",
            " - 0s - loss: 7.1474 - acc: 0.3125 - val_loss: 12.9472 - val_acc: 0.2000\n",
            "Epoch 457/1000\n",
            " - 0s - loss: 7.2957 - acc: 0.2500 - val_loss: 10.5840 - val_acc: 0.3000\n",
            "Epoch 458/1000\n",
            " - 0s - loss: 7.3748 - acc: 0.2250 - val_loss: 10.2152 - val_acc: 0.2500\n",
            "Epoch 459/1000\n",
            " - 0s - loss: 7.1619 - acc: 0.2375 - val_loss: 13.2977 - val_acc: 0.2000\n",
            "Epoch 460/1000\n",
            " - 0s - loss: 7.0631 - acc: 0.3000 - val_loss: 13.0941 - val_acc: 0.2500\n",
            "Epoch 461/1000\n",
            " - 0s - loss: 7.1271 - acc: 0.2625 - val_loss: 12.9975 - val_acc: 0.2000\n",
            "Epoch 462/1000\n",
            " - 0s - loss: 7.2448 - acc: 0.3000 - val_loss: 10.6669 - val_acc: 0.2500\n",
            "Epoch 463/1000\n",
            " - 0s - loss: 7.3115 - acc: 0.2375 - val_loss: 12.9149 - val_acc: 0.2000\n",
            "Epoch 464/1000\n",
            " - 0s - loss: 7.1244 - acc: 0.2750 - val_loss: 10.3770 - val_acc: 0.2500\n",
            "Epoch 465/1000\n",
            " - 0s - loss: 7.1943 - acc: 0.2625 - val_loss: 12.6752 - val_acc: 0.1500\n",
            "Epoch 466/1000\n",
            " - 0s - loss: 7.2520 - acc: 0.2375 - val_loss: 11.6140 - val_acc: 0.2500\n",
            "Epoch 467/1000\n",
            " - 0s - loss: 7.0373 - acc: 0.2625 - val_loss: 11.4551 - val_acc: 0.2500\n",
            "Epoch 468/1000\n",
            " - 0s - loss: 7.0878 - acc: 0.2500 - val_loss: 13.3167 - val_acc: 0.2500\n",
            "Epoch 469/1000\n",
            " - 0s - loss: 7.3802 - acc: 0.2875 - val_loss: 14.0571 - val_acc: 0.2500\n",
            "Epoch 470/1000\n",
            " - 0s - loss: 6.9161 - acc: 0.2625 - val_loss: 16.3196 - val_acc: 0.2000\n",
            "Epoch 471/1000\n",
            " - 0s - loss: 7.4393 - acc: 0.2125 - val_loss: 12.6478 - val_acc: 0.1500\n",
            "Epoch 472/1000\n",
            " - 0s - loss: 6.9079 - acc: 0.3250 - val_loss: 12.2883 - val_acc: 0.1500\n",
            "Epoch 473/1000\n",
            " - 0s - loss: 6.9684 - acc: 0.2875 - val_loss: 11.2842 - val_acc: 0.3000\n",
            "Epoch 474/1000\n",
            " - 0s - loss: 7.3823 - acc: 0.2375 - val_loss: 9.8288 - val_acc: 0.2500\n",
            "Epoch 475/1000\n",
            " - 0s - loss: 7.0759 - acc: 0.1875 - val_loss: 14.1263 - val_acc: 0.2500\n",
            "Epoch 476/1000\n",
            " - 0s - loss: 7.1349 - acc: 0.2375 - val_loss: 12.6952 - val_acc: 0.2500\n",
            "Epoch 477/1000\n",
            " - 0s - loss: 7.1882 - acc: 0.2750 - val_loss: 13.3642 - val_acc: 0.2500\n",
            "Epoch 478/1000\n",
            " - 0s - loss: 7.0130 - acc: 0.2500 - val_loss: 12.0195 - val_acc: 0.1500\n",
            "Epoch 479/1000\n",
            " - 0s - loss: 7.2143 - acc: 0.2125 - val_loss: 12.1855 - val_acc: 0.1500\n",
            "Epoch 480/1000\n",
            " - 0s - loss: 7.1805 - acc: 0.2625 - val_loss: 13.0342 - val_acc: 0.2000\n",
            "Epoch 481/1000\n",
            " - 0s - loss: 6.9440 - acc: 0.2500 - val_loss: 15.3657 - val_acc: 0.2000\n",
            "Epoch 482/1000\n",
            " - 0s - loss: 7.0468 - acc: 0.3000 - val_loss: 11.7677 - val_acc: 0.1500\n",
            "Epoch 483/1000\n",
            " - 0s - loss: 7.0045 - acc: 0.2500 - val_loss: 14.1635 - val_acc: 0.2500\n",
            "Epoch 484/1000\n",
            " - 0s - loss: 7.1331 - acc: 0.2750 - val_loss: 12.1632 - val_acc: 0.1500\n",
            "Epoch 485/1000\n",
            " - 0s - loss: 7.1094 - acc: 0.2500 - val_loss: 15.0704 - val_acc: 0.2500\n",
            "Epoch 486/1000\n",
            " - 0s - loss: 7.1758 - acc: 0.2625 - val_loss: 15.3593 - val_acc: 0.2500\n",
            "Epoch 487/1000\n",
            " - 0s - loss: 7.4445 - acc: 0.2500 - val_loss: 12.2732 - val_acc: 0.2500\n",
            "Epoch 488/1000\n",
            " - 0s - loss: 7.0501 - acc: 0.2375 - val_loss: 12.7746 - val_acc: 0.2500\n",
            "Epoch 489/1000\n",
            " - 0s - loss: 6.9620 - acc: 0.2750 - val_loss: 11.1972 - val_acc: 0.2500\n",
            "Epoch 490/1000\n",
            " - 0s - loss: 6.9566 - acc: 0.2375 - val_loss: 15.4862 - val_acc: 0.2500\n",
            "Epoch 491/1000\n",
            " - 0s - loss: 7.0432 - acc: 0.2500 - val_loss: 11.1988 - val_acc: 0.3000\n",
            "Epoch 492/1000\n",
            " - 0s - loss: 7.0058 - acc: 0.1875 - val_loss: 13.2806 - val_acc: 0.2000\n",
            "Epoch 493/1000\n",
            " - 0s - loss: 6.9443 - acc: 0.2875 - val_loss: 14.8645 - val_acc: 0.2500\n",
            "Epoch 494/1000\n",
            " - 0s - loss: 6.9776 - acc: 0.3000 - val_loss: 12.6454 - val_acc: 0.1500\n",
            "Epoch 495/1000\n",
            " - 0s - loss: 6.8590 - acc: 0.2000 - val_loss: 15.8458 - val_acc: 0.2000\n",
            "Epoch 496/1000\n",
            " - 0s - loss: 7.4013 - acc: 0.2250 - val_loss: 14.8062 - val_acc: 0.2500\n",
            "Epoch 497/1000\n",
            " - 0s - loss: 7.5003 - acc: 0.2625 - val_loss: 11.7445 - val_acc: 0.1500\n",
            "Epoch 498/1000\n",
            " - 0s - loss: 7.0759 - acc: 0.2375 - val_loss: 12.1595 - val_acc: 0.1500\n",
            "Epoch 499/1000\n",
            " - 0s - loss: 7.2970 - acc: 0.2375 - val_loss: 12.8194 - val_acc: 0.2500\n",
            "Epoch 500/1000\n",
            " - 0s - loss: 6.9025 - acc: 0.2625 - val_loss: 11.3915 - val_acc: 0.2500\n",
            "Epoch 501/1000\n",
            " - 0s - loss: 6.7658 - acc: 0.2125 - val_loss: 15.3722 - val_acc: 0.2500\n",
            "Epoch 502/1000\n",
            " - 0s - loss: 6.9684 - acc: 0.2625 - val_loss: 13.6083 - val_acc: 0.2500\n",
            "Epoch 503/1000\n",
            " - 0s - loss: 7.0267 - acc: 0.2500 - val_loss: 10.7286 - val_acc: 0.2000\n",
            "Epoch 504/1000\n",
            " - 0s - loss: 6.8989 - acc: 0.2625 - val_loss: 13.4771 - val_acc: 0.2000\n",
            "Epoch 505/1000\n",
            " - 0s - loss: 7.0818 - acc: 0.3000 - val_loss: 12.8321 - val_acc: 0.2500\n",
            "Epoch 506/1000\n",
            " - 0s - loss: 7.1653 - acc: 0.2375 - val_loss: 15.5510 - val_acc: 0.2000\n",
            "Epoch 507/1000\n",
            " - 0s - loss: 7.1554 - acc: 0.2375 - val_loss: 14.1653 - val_acc: 0.2500\n",
            "Epoch 508/1000\n",
            " - 0s - loss: 7.4627 - acc: 0.2625 - val_loss: 10.7335 - val_acc: 0.2000\n",
            "Epoch 509/1000\n",
            " - 0s - loss: 7.3154 - acc: 0.2375 - val_loss: 11.0946 - val_acc: 0.3000\n",
            "Epoch 510/1000\n",
            " - 0s - loss: 7.2536 - acc: 0.2375 - val_loss: 11.2025 - val_acc: 0.1500\n",
            "Epoch 511/1000\n",
            " - 0s - loss: 6.9778 - acc: 0.2750 - val_loss: 11.7662 - val_acc: 0.2000\n",
            "Epoch 512/1000\n",
            " - 0s - loss: 6.7950 - acc: 0.2625 - val_loss: 15.8859 - val_acc: 0.2500\n",
            "Epoch 513/1000\n",
            " - 0s - loss: 6.9412 - acc: 0.2125 - val_loss: 10.8522 - val_acc: 0.3000\n",
            "Epoch 514/1000\n",
            " - 0s - loss: 6.9993 - acc: 0.2750 - val_loss: 10.8055 - val_acc: 0.3000\n",
            "Epoch 515/1000\n",
            " - 0s - loss: 7.2380 - acc: 0.3125 - val_loss: 11.3439 - val_acc: 0.2500\n",
            "Epoch 516/1000\n",
            " - 0s - loss: 7.1660 - acc: 0.2500 - val_loss: 10.3149 - val_acc: 0.3500\n",
            "Epoch 517/1000\n",
            " - 0s - loss: 7.0410 - acc: 0.2125 - val_loss: 10.8797 - val_acc: 0.1500\n",
            "Epoch 518/1000\n",
            " - 0s - loss: 6.9964 - acc: 0.2750 - val_loss: 13.0619 - val_acc: 0.2500\n",
            "Epoch 519/1000\n",
            " - 0s - loss: 6.7985 - acc: 0.2375 - val_loss: 11.0006 - val_acc: 0.2500\n",
            "Epoch 520/1000\n",
            " - 0s - loss: 6.9417 - acc: 0.1875 - val_loss: 13.4275 - val_acc: 0.2500\n",
            "Epoch 521/1000\n",
            " - 0s - loss: 7.1251 - acc: 0.2125 - val_loss: 10.1056 - val_acc: 0.3000\n",
            "Epoch 522/1000\n",
            " - 0s - loss: 7.0158 - acc: 0.2750 - val_loss: 13.1357 - val_acc: 0.2500\n",
            "Epoch 523/1000\n",
            " - 0s - loss: 6.9491 - acc: 0.2125 - val_loss: 12.5373 - val_acc: 0.1500\n",
            "Epoch 524/1000\n",
            " - 0s - loss: 7.1345 - acc: 0.2625 - val_loss: 12.6069 - val_acc: 0.1500\n",
            "Epoch 525/1000\n",
            " - 0s - loss: 6.9633 - acc: 0.2500 - val_loss: 11.4633 - val_acc: 0.1500\n",
            "Epoch 526/1000\n",
            " - 0s - loss: 7.0382 - acc: 0.2875 - val_loss: 13.4721 - val_acc: 0.2500\n",
            "Epoch 527/1000\n",
            " - 0s - loss: 7.2121 - acc: 0.2375 - val_loss: 16.4555 - val_acc: 0.2000\n",
            "Epoch 528/1000\n",
            " - 0s - loss: 7.1438 - acc: 0.2750 - val_loss: 12.3587 - val_acc: 0.2000\n",
            "Epoch 529/1000\n",
            " - 0s - loss: 7.1194 - acc: 0.2250 - val_loss: 11.1911 - val_acc: 0.1500\n",
            "Epoch 530/1000\n",
            " - 0s - loss: 6.9571 - acc: 0.2250 - val_loss: 11.4148 - val_acc: 0.2000\n",
            "Epoch 531/1000\n",
            " - 0s - loss: 6.8778 - acc: 0.3250 - val_loss: 12.4462 - val_acc: 0.1500\n",
            "Epoch 532/1000\n",
            " - 0s - loss: 7.1556 - acc: 0.2250 - val_loss: 13.8947 - val_acc: 0.2000\n",
            "Epoch 533/1000\n",
            " - 0s - loss: 6.9420 - acc: 0.2750 - val_loss: 10.9408 - val_acc: 0.3000\n",
            "Epoch 534/1000\n",
            " - 0s - loss: 7.0687 - acc: 0.2375 - val_loss: 11.3560 - val_acc: 0.2500\n",
            "Epoch 535/1000\n",
            " - 0s - loss: 7.1890 - acc: 0.2250 - val_loss: 14.0797 - val_acc: 0.2500\n",
            "Epoch 536/1000\n",
            " - 0s - loss: 7.0612 - acc: 0.2250 - val_loss: 10.4040 - val_acc: 0.3000\n",
            "Epoch 537/1000\n",
            " - 0s - loss: 7.2409 - acc: 0.2500 - val_loss: 15.0556 - val_acc: 0.2000\n",
            "Epoch 538/1000\n",
            " - 0s - loss: 6.8272 - acc: 0.2500 - val_loss: 11.0935 - val_acc: 0.3000\n",
            "Epoch 539/1000\n",
            " - 0s - loss: 6.9946 - acc: 0.2000 - val_loss: 14.4258 - val_acc: 0.2500\n",
            "Epoch 540/1000\n",
            " - 0s - loss: 6.6970 - acc: 0.2625 - val_loss: 11.1755 - val_acc: 0.3000\n",
            "Epoch 541/1000\n",
            " - 0s - loss: 7.1298 - acc: 0.2000 - val_loss: 15.2957 - val_acc: 0.2500\n",
            "Epoch 542/1000\n",
            " - 0s - loss: 6.9092 - acc: 0.2625 - val_loss: 12.6253 - val_acc: 0.2000\n",
            "Epoch 543/1000\n",
            " - 0s - loss: 6.9740 - acc: 0.2625 - val_loss: 11.9284 - val_acc: 0.1500\n",
            "Epoch 544/1000\n",
            " - 0s - loss: 7.0714 - acc: 0.2375 - val_loss: 10.9046 - val_acc: 0.2000\n",
            "Epoch 545/1000\n",
            " - 0s - loss: 7.3610 - acc: 0.1750 - val_loss: 15.8994 - val_acc: 0.2000\n",
            "Epoch 546/1000\n",
            " - 0s - loss: 7.0303 - acc: 0.2125 - val_loss: 11.1454 - val_acc: 0.3000\n",
            "Epoch 547/1000\n",
            " - 0s - loss: 6.9303 - acc: 0.3000 - val_loss: 12.3941 - val_acc: 0.1500\n",
            "Epoch 548/1000\n",
            " - 0s - loss: 6.9402 - acc: 0.2625 - val_loss: 15.0375 - val_acc: 0.2000\n",
            "Epoch 549/1000\n",
            " - 0s - loss: 7.4724 - acc: 0.2250 - val_loss: 12.9608 - val_acc: 0.2500\n",
            "Epoch 550/1000\n",
            " - 0s - loss: 7.1419 - acc: 0.2000 - val_loss: 14.2530 - val_acc: 0.2000\n",
            "Epoch 551/1000\n",
            " - 0s - loss: 6.9310 - acc: 0.2000 - val_loss: 14.6143 - val_acc: 0.2000\n",
            "Epoch 552/1000\n",
            " - 0s - loss: 7.0348 - acc: 0.1875 - val_loss: 15.2309 - val_acc: 0.2000\n",
            "Epoch 553/1000\n",
            " - 0s - loss: 7.2272 - acc: 0.2375 - val_loss: 13.4978 - val_acc: 0.2500\n",
            "Epoch 554/1000\n",
            " - 0s - loss: 6.7581 - acc: 0.3000 - val_loss: 11.3181 - val_acc: 0.2500\n",
            "Epoch 555/1000\n",
            " - 0s - loss: 7.1380 - acc: 0.2750 - val_loss: 11.5268 - val_acc: 0.1500\n",
            "Epoch 556/1000\n",
            " - 0s - loss: 6.9049 - acc: 0.2875 - val_loss: 12.2791 - val_acc: 0.2000\n",
            "Epoch 557/1000\n",
            " - 0s - loss: 6.9283 - acc: 0.2750 - val_loss: 11.2361 - val_acc: 0.1500\n",
            "Epoch 558/1000\n",
            " - 0s - loss: 6.9626 - acc: 0.2500 - val_loss: 11.3162 - val_acc: 0.1500\n",
            "Epoch 559/1000\n",
            " - 0s - loss: 7.5120 - acc: 0.2375 - val_loss: 12.4037 - val_acc: 0.1500\n",
            "Epoch 560/1000\n",
            " - 0s - loss: 6.9562 - acc: 0.2125 - val_loss: 13.0031 - val_acc: 0.2000\n",
            "Epoch 561/1000\n",
            " - 0s - loss: 7.1598 - acc: 0.2625 - val_loss: 11.8487 - val_acc: 0.1500\n",
            "Epoch 562/1000\n",
            " - 0s - loss: 6.8895 - acc: 0.2625 - val_loss: 13.0766 - val_acc: 0.2500\n",
            "Epoch 563/1000\n",
            " - 0s - loss: 6.9601 - acc: 0.2625 - val_loss: 10.4891 - val_acc: 0.2500\n",
            "Epoch 564/1000\n",
            " - 0s - loss: 7.0410 - acc: 0.2375 - val_loss: 12.4368 - val_acc: 0.1500\n",
            "Epoch 565/1000\n",
            " - 0s - loss: 6.9041 - acc: 0.3125 - val_loss: 13.0590 - val_acc: 0.2000\n",
            "Epoch 566/1000\n",
            " - 0s - loss: 6.8400 - acc: 0.3250 - val_loss: 11.7668 - val_acc: 0.2000\n",
            "Epoch 567/1000\n",
            " - 0s - loss: 7.0168 - acc: 0.2000 - val_loss: 9.9490 - val_acc: 0.2500\n",
            "Epoch 568/1000\n",
            " - 0s - loss: 7.2356 - acc: 0.1750 - val_loss: 11.5797 - val_acc: 0.1500\n",
            "Epoch 569/1000\n",
            " - 0s - loss: 7.4363 - acc: 0.2375 - val_loss: 11.3401 - val_acc: 0.2000\n",
            "Epoch 570/1000\n",
            " - 0s - loss: 6.9654 - acc: 0.2125 - val_loss: 17.1486 - val_acc: 0.2000\n",
            "Epoch 571/1000\n",
            " - 0s - loss: 6.9193 - acc: 0.2250 - val_loss: 13.4265 - val_acc: 0.2000\n",
            "Epoch 572/1000\n",
            " - 0s - loss: 6.8687 - acc: 0.2375 - val_loss: 13.0872 - val_acc: 0.1500\n",
            "Epoch 573/1000\n",
            " - 0s - loss: 6.8657 - acc: 0.2500 - val_loss: 12.8286 - val_acc: 0.1500\n",
            "Epoch 574/1000\n",
            " - 0s - loss: 6.8128 - acc: 0.2250 - val_loss: 14.6723 - val_acc: 0.2500\n",
            "Epoch 575/1000\n",
            " - 0s - loss: 7.0099 - acc: 0.1750 - val_loss: 13.3719 - val_acc: 0.2000\n",
            "Epoch 576/1000\n",
            " - 0s - loss: 6.7789 - acc: 0.2875 - val_loss: 11.4071 - val_acc: 0.2000\n",
            "Epoch 577/1000\n",
            " - 0s - loss: 6.9305 - acc: 0.2375 - val_loss: 11.5082 - val_acc: 0.1500\n",
            "Epoch 578/1000\n",
            " - 0s - loss: 6.9949 - acc: 0.2625 - val_loss: 12.1701 - val_acc: 0.1500\n",
            "Epoch 579/1000\n",
            " - 0s - loss: 6.8521 - acc: 0.3000 - val_loss: 12.3615 - val_acc: 0.1500\n",
            "Epoch 580/1000\n",
            " - 0s - loss: 6.7300 - acc: 0.3125 - val_loss: 11.1556 - val_acc: 0.2000\n",
            "Epoch 581/1000\n",
            " - 0s - loss: 6.8692 - acc: 0.1875 - val_loss: 13.7496 - val_acc: 0.2500\n",
            "Epoch 582/1000\n",
            " - 0s - loss: 7.3562 - acc: 0.3500 - val_loss: 12.2482 - val_acc: 0.2500\n",
            "Epoch 583/1000\n",
            " - 0s - loss: 6.9487 - acc: 0.2375 - val_loss: 12.8380 - val_acc: 0.2000\n",
            "Epoch 584/1000\n",
            " - 0s - loss: 6.9819 - acc: 0.2625 - val_loss: 14.6455 - val_acc: 0.2500\n",
            "Epoch 585/1000\n",
            " - 0s - loss: 6.6264 - acc: 0.3000 - val_loss: 10.3810 - val_acc: 0.2500\n",
            "Epoch 586/1000\n",
            " - 0s - loss: 6.9374 - acc: 0.2375 - val_loss: 14.1846 - val_acc: 0.2000\n",
            "Epoch 587/1000\n",
            " - 0s - loss: 6.6583 - acc: 0.2750 - val_loss: 11.1457 - val_acc: 0.2500\n",
            "Epoch 588/1000\n",
            " - 0s - loss: 6.9059 - acc: 0.2375 - val_loss: 10.8800 - val_acc: 0.3000\n",
            "Epoch 589/1000\n",
            " - 0s - loss: 6.4813 - acc: 0.2375 - val_loss: 19.0458 - val_acc: 0.2000\n",
            "Epoch 590/1000\n",
            " - 0s - loss: 7.0881 - acc: 0.2250 - val_loss: 11.1824 - val_acc: 0.2000\n",
            "Epoch 591/1000\n",
            " - 0s - loss: 6.8043 - acc: 0.2625 - val_loss: 12.6770 - val_acc: 0.2000\n",
            "Epoch 592/1000\n",
            " - 0s - loss: 6.8597 - acc: 0.2875 - val_loss: 11.7738 - val_acc: 0.1500\n",
            "Epoch 593/1000\n",
            " - 0s - loss: 6.8661 - acc: 0.2125 - val_loss: 10.6375 - val_acc: 0.2500\n",
            "Epoch 594/1000\n",
            " - 0s - loss: 6.7520 - acc: 0.2625 - val_loss: 12.4247 - val_acc: 0.2000\n",
            "Epoch 595/1000\n",
            " - 0s - loss: 7.4929 - acc: 0.1875 - val_loss: 13.1533 - val_acc: 0.2500\n",
            "Epoch 596/1000\n",
            " - 0s - loss: 6.8611 - acc: 0.2625 - val_loss: 14.8916 - val_acc: 0.2500\n",
            "Epoch 597/1000\n",
            " - 0s - loss: 6.7635 - acc: 0.2750 - val_loss: 10.1144 - val_acc: 0.3000\n",
            "Epoch 598/1000\n",
            " - 0s - loss: 6.8630 - acc: 0.2375 - val_loss: 11.8222 - val_acc: 0.1500\n",
            "Epoch 599/1000\n",
            " - 0s - loss: 6.8487 - acc: 0.2625 - val_loss: 11.3097 - val_acc: 0.2000\n",
            "Epoch 600/1000\n",
            " - 0s - loss: 6.7775 - acc: 0.2750 - val_loss: 12.2339 - val_acc: 0.2000\n",
            "Epoch 601/1000\n",
            " - 0s - loss: 6.8196 - acc: 0.2875 - val_loss: 12.0130 - val_acc: 0.2000\n",
            "Epoch 602/1000\n",
            " - 0s - loss: 7.0004 - acc: 0.2750 - val_loss: 12.5107 - val_acc: 0.2000\n",
            "Epoch 603/1000\n",
            " - 0s - loss: 7.0324 - acc: 0.2375 - val_loss: 12.0716 - val_acc: 0.2000\n",
            "Epoch 604/1000\n",
            " - 0s - loss: 6.6502 - acc: 0.3000 - val_loss: 10.9643 - val_acc: 0.2500\n",
            "Epoch 605/1000\n",
            " - 0s - loss: 6.7501 - acc: 0.2625 - val_loss: 12.4560 - val_acc: 0.2000\n",
            "Epoch 606/1000\n",
            " - 0s - loss: 6.7456 - acc: 0.2875 - val_loss: 10.3690 - val_acc: 0.2500\n",
            "Epoch 607/1000\n",
            " - 0s - loss: 6.8308 - acc: 0.2375 - val_loss: 10.9542 - val_acc: 0.2500\n",
            "Epoch 608/1000\n",
            " - 0s - loss: 6.8047 - acc: 0.2000 - val_loss: 14.6530 - val_acc: 0.2500\n",
            "Epoch 609/1000\n",
            " - 0s - loss: 6.8966 - acc: 0.2125 - val_loss: 12.2723 - val_acc: 0.1500\n",
            "Epoch 610/1000\n",
            " - 0s - loss: 6.9136 - acc: 0.2750 - val_loss: 9.8563 - val_acc: 0.3000\n",
            "Epoch 611/1000\n",
            " - 0s - loss: 7.0668 - acc: 0.2375 - val_loss: 10.3224 - val_acc: 0.2500\n",
            "Epoch 612/1000\n",
            " - 0s - loss: 7.0400 - acc: 0.2875 - val_loss: 12.8461 - val_acc: 0.2500\n",
            "Epoch 613/1000\n",
            " - 0s - loss: 6.7876 - acc: 0.2875 - val_loss: 11.1559 - val_acc: 0.2500\n",
            "Epoch 614/1000\n",
            " - 0s - loss: 7.3732 - acc: 0.2000 - val_loss: 14.2801 - val_acc: 0.2500\n",
            "Epoch 615/1000\n",
            " - 0s - loss: 6.7263 - acc: 0.2750 - val_loss: 11.2568 - val_acc: 0.2000\n",
            "Epoch 616/1000\n",
            " - 0s - loss: 7.0352 - acc: 0.2500 - val_loss: 13.1359 - val_acc: 0.2000\n",
            "Epoch 617/1000\n",
            " - 0s - loss: 6.7263 - acc: 0.2875 - val_loss: 10.2404 - val_acc: 0.3500\n",
            "Epoch 618/1000\n",
            " - 0s - loss: 6.9949 - acc: 0.2500 - val_loss: 10.7725 - val_acc: 0.3000\n",
            "Epoch 619/1000\n",
            " - 0s - loss: 7.0272 - acc: 0.2375 - val_loss: 11.4780 - val_acc: 0.1500\n",
            "Epoch 620/1000\n",
            " - 0s - loss: 6.9250 - acc: 0.2625 - val_loss: 12.1333 - val_acc: 0.1500\n",
            "Epoch 621/1000\n",
            " - 0s - loss: 6.8482 - acc: 0.2250 - val_loss: 11.7721 - val_acc: 0.1500\n",
            "Epoch 622/1000\n",
            " - 0s - loss: 6.9771 - acc: 0.2375 - val_loss: 12.5549 - val_acc: 0.2000\n",
            "Epoch 623/1000\n",
            " - 0s - loss: 7.5387 - acc: 0.1625 - val_loss: 11.9172 - val_acc: 0.2000\n",
            "Epoch 624/1000\n",
            " - 0s - loss: 6.7157 - acc: 0.2750 - val_loss: 10.4376 - val_acc: 0.2500\n",
            "Epoch 625/1000\n",
            " - 0s - loss: 6.7318 - acc: 0.2500 - val_loss: 12.2127 - val_acc: 0.1500\n",
            "Epoch 626/1000\n",
            " - 0s - loss: 6.8388 - acc: 0.3125 - val_loss: 11.5951 - val_acc: 0.1500\n",
            "Epoch 627/1000\n",
            " - 0s - loss: 6.7013 - acc: 0.2500 - val_loss: 14.4037 - val_acc: 0.2500\n",
            "Epoch 628/1000\n",
            " - 0s - loss: 7.1679 - acc: 0.2625 - val_loss: 13.4602 - val_acc: 0.2500\n",
            "Epoch 629/1000\n",
            " - 0s - loss: 6.7522 - acc: 0.2875 - val_loss: 11.6278 - val_acc: 0.1500\n",
            "Epoch 630/1000\n",
            " - 0s - loss: 6.6891 - acc: 0.1875 - val_loss: 14.6900 - val_acc: 0.2000\n",
            "Epoch 631/1000\n",
            " - 0s - loss: 7.6259 - acc: 0.2125 - val_loss: 11.3349 - val_acc: 0.1500\n",
            "Epoch 632/1000\n",
            " - 0s - loss: 6.9083 - acc: 0.2625 - val_loss: 12.0710 - val_acc: 0.2000\n",
            "Epoch 633/1000\n",
            " - 0s - loss: 6.9596 - acc: 0.3125 - val_loss: 11.0029 - val_acc: 0.2000\n",
            "Epoch 634/1000\n",
            " - 0s - loss: 6.7852 - acc: 0.2250 - val_loss: 10.9339 - val_acc: 0.3000\n",
            "Epoch 635/1000\n",
            " - 0s - loss: 7.1621 - acc: 0.2000 - val_loss: 10.2722 - val_acc: 0.3000\n",
            "Epoch 636/1000\n",
            " - 0s - loss: 6.7376 - acc: 0.1875 - val_loss: 14.5000 - val_acc: 0.2500\n",
            "Epoch 637/1000\n",
            " - 0s - loss: 7.2139 - acc: 0.2125 - val_loss: 11.3179 - val_acc: 0.2000\n",
            "Epoch 638/1000\n",
            " - 0s - loss: 6.8105 - acc: 0.2000 - val_loss: 12.7062 - val_acc: 0.2500\n",
            "Epoch 639/1000\n",
            " - 0s - loss: 6.9305 - acc: 0.2250 - val_loss: 13.5790 - val_acc: 0.2500\n",
            "Epoch 640/1000\n",
            " - 0s - loss: 6.9909 - acc: 0.2625 - val_loss: 11.8250 - val_acc: 0.1500\n",
            "Epoch 641/1000\n",
            " - 0s - loss: 6.7173 - acc: 0.2375 - val_loss: 12.3646 - val_acc: 0.2000\n",
            "Epoch 642/1000\n",
            " - 0s - loss: 6.8079 - acc: 0.2500 - val_loss: 11.8839 - val_acc: 0.1500\n",
            "Epoch 643/1000\n",
            " - 0s - loss: 7.0647 - acc: 0.2625 - val_loss: 11.7245 - val_acc: 0.2000\n",
            "Epoch 644/1000\n",
            " - 0s - loss: 6.6418 - acc: 0.2750 - val_loss: 11.8420 - val_acc: 0.1500\n",
            "Epoch 645/1000\n",
            " - 0s - loss: 6.7313 - acc: 0.2625 - val_loss: 13.3907 - val_acc: 0.2500\n",
            "Epoch 646/1000\n",
            " - 0s - loss: 6.7694 - acc: 0.2625 - val_loss: 11.2971 - val_acc: 0.1500\n",
            "Epoch 647/1000\n",
            " - 0s - loss: 6.8472 - acc: 0.2750 - val_loss: 12.0332 - val_acc: 0.1500\n",
            "Epoch 648/1000\n",
            " - 0s - loss: 6.8816 - acc: 0.2375 - val_loss: 10.8329 - val_acc: 0.3000\n",
            "Epoch 649/1000\n",
            " - 0s - loss: 6.7909 - acc: 0.2500 - val_loss: 13.2664 - val_acc: 0.2500\n",
            "Epoch 650/1000\n",
            " - 0s - loss: 6.7429 - acc: 0.3000 - val_loss: 15.0616 - val_acc: 0.2500\n",
            "Epoch 651/1000\n",
            " - 0s - loss: 6.9040 - acc: 0.2250 - val_loss: 13.0036 - val_acc: 0.2500\n",
            "Epoch 652/1000\n",
            " - 0s - loss: 6.7308 - acc: 0.2750 - val_loss: 10.8999 - val_acc: 0.2500\n",
            "Epoch 653/1000\n",
            " - 0s - loss: 6.7376 - acc: 0.2625 - val_loss: 13.1370 - val_acc: 0.2000\n",
            "Epoch 654/1000\n",
            " - 0s - loss: 6.7467 - acc: 0.2000 - val_loss: 14.9915 - val_acc: 0.2000\n",
            "Epoch 655/1000\n",
            " - 0s - loss: 6.8148 - acc: 0.2375 - val_loss: 10.8836 - val_acc: 0.2500\n",
            "Epoch 656/1000\n",
            " - 0s - loss: 7.1116 - acc: 0.2375 - val_loss: 10.9550 - val_acc: 0.3000\n",
            "Epoch 657/1000\n",
            " - 0s - loss: 6.7534 - acc: 0.2000 - val_loss: 13.5798 - val_acc: 0.2500\n",
            "Epoch 658/1000\n",
            " - 0s - loss: 6.5636 - acc: 0.2375 - val_loss: 11.8620 - val_acc: 0.1500\n",
            "Epoch 659/1000\n",
            " - 0s - loss: 6.8366 - acc: 0.3000 - val_loss: 11.9760 - val_acc: 0.1500\n",
            "Epoch 660/1000\n",
            " - 0s - loss: 7.0826 - acc: 0.3250 - val_loss: 12.0131 - val_acc: 0.2000\n",
            "Epoch 661/1000\n",
            " - 0s - loss: 6.7187 - acc: 0.2500 - val_loss: 11.2436 - val_acc: 0.2500\n",
            "Epoch 662/1000\n",
            " - 0s - loss: 6.8417 - acc: 0.1750 - val_loss: 12.1590 - val_acc: 0.1500\n",
            "Epoch 663/1000\n",
            " - 0s - loss: 6.6773 - acc: 0.2875 - val_loss: 13.0223 - val_acc: 0.2000\n",
            "Epoch 664/1000\n",
            " - 0s - loss: 6.6064 - acc: 0.2250 - val_loss: 10.0957 - val_acc: 0.2500\n",
            "Epoch 665/1000\n",
            " - 0s - loss: 6.9142 - acc: 0.1750 - val_loss: 11.2056 - val_acc: 0.1500\n",
            "Epoch 666/1000\n",
            " - 0s - loss: 6.7640 - acc: 0.2250 - val_loss: 11.9330 - val_acc: 0.1500\n",
            "Epoch 667/1000\n",
            " - 0s - loss: 6.6441 - acc: 0.2500 - val_loss: 11.7475 - val_acc: 0.1500\n",
            "Epoch 668/1000\n",
            " - 0s - loss: 6.5957 - acc: 0.2750 - val_loss: 10.9833 - val_acc: 0.2500\n",
            "Epoch 669/1000\n",
            " - 0s - loss: 6.5682 - acc: 0.2375 - val_loss: 15.3142 - val_acc: 0.2500\n",
            "Epoch 670/1000\n",
            " - 0s - loss: 6.6671 - acc: 0.2750 - val_loss: 11.8097 - val_acc: 0.2500\n",
            "Epoch 671/1000\n",
            " - 0s - loss: 6.6920 - acc: 0.2625 - val_loss: 12.1794 - val_acc: 0.1500\n",
            "Epoch 672/1000\n",
            " - 0s - loss: 6.7515 - acc: 0.2625 - val_loss: 10.9594 - val_acc: 0.1500\n",
            "Epoch 673/1000\n",
            " - 0s - loss: 6.7415 - acc: 0.3125 - val_loss: 15.1503 - val_acc: 0.2000\n",
            "Epoch 674/1000\n",
            " - 0s - loss: 6.6861 - acc: 0.2875 - val_loss: 14.9308 - val_acc: 0.2000\n",
            "Epoch 675/1000\n",
            " - 0s - loss: 6.6796 - acc: 0.2375 - val_loss: 11.8249 - val_acc: 0.1500\n",
            "Epoch 676/1000\n",
            " - 0s - loss: 6.6379 - acc: 0.2625 - val_loss: 14.9764 - val_acc: 0.2500\n",
            "Epoch 677/1000\n",
            " - 0s - loss: 7.1237 - acc: 0.2625 - val_loss: 11.6711 - val_acc: 0.2000\n",
            "Epoch 678/1000\n",
            " - 0s - loss: 6.6835 - acc: 0.2875 - val_loss: 13.2300 - val_acc: 0.2500\n",
            "Epoch 679/1000\n",
            " - 0s - loss: 6.7597 - acc: 0.2500 - val_loss: 10.9141 - val_acc: 0.2500\n",
            "Epoch 680/1000\n",
            " - 0s - loss: 6.6325 - acc: 0.2625 - val_loss: 12.8873 - val_acc: 0.2000\n",
            "Epoch 681/1000\n",
            " - 0s - loss: 6.8798 - acc: 0.2000 - val_loss: 14.6485 - val_acc: 0.3000\n",
            "Epoch 682/1000\n",
            " - 0s - loss: 7.6847 - acc: 0.2125 - val_loss: 13.1655 - val_acc: 0.2500\n",
            "Epoch 683/1000\n",
            " - 0s - loss: 6.7869 - acc: 0.2875 - val_loss: 11.9760 - val_acc: 0.1500\n",
            "Epoch 684/1000\n",
            " - 0s - loss: 6.7609 - acc: 0.2500 - val_loss: 13.7976 - val_acc: 0.2500\n",
            "Epoch 685/1000\n",
            " - 0s - loss: 6.7940 - acc: 0.2500 - val_loss: 12.5126 - val_acc: 0.2500\n",
            "Epoch 686/1000\n",
            " - 0s - loss: 6.6437 - acc: 0.2375 - val_loss: 11.9985 - val_acc: 0.2000\n",
            "Epoch 687/1000\n",
            " - 0s - loss: 6.8561 - acc: 0.2500 - val_loss: 10.4272 - val_acc: 0.2500\n",
            "Epoch 688/1000\n",
            " - 0s - loss: 6.5893 - acc: 0.2375 - val_loss: 12.4603 - val_acc: 0.2500\n",
            "Epoch 689/1000\n",
            " - 0s - loss: 6.7686 - acc: 0.2250 - val_loss: 10.1055 - val_acc: 0.3000\n",
            "Epoch 690/1000\n",
            " - 0s - loss: 6.5185 - acc: 0.1875 - val_loss: 13.4310 - val_acc: 0.2500\n",
            "Epoch 691/1000\n",
            " - 0s - loss: 6.6554 - acc: 0.2625 - val_loss: 11.1168 - val_acc: 0.1500\n",
            "Epoch 692/1000\n",
            " - 0s - loss: 6.5861 - acc: 0.3250 - val_loss: 11.1505 - val_acc: 0.2500\n",
            "Epoch 693/1000\n",
            " - 0s - loss: 6.7529 - acc: 0.2000 - val_loss: 17.7775 - val_acc: 0.2500\n",
            "Epoch 694/1000\n",
            " - 0s - loss: 6.7782 - acc: 0.2375 - val_loss: 12.0479 - val_acc: 0.1500\n",
            "Epoch 695/1000\n",
            " - 0s - loss: 6.6182 - acc: 0.2625 - val_loss: 12.0129 - val_acc: 0.1500\n",
            "Epoch 696/1000\n",
            " - 0s - loss: 6.4523 - acc: 0.2500 - val_loss: 13.5646 - val_acc: 0.2500\n",
            "Epoch 697/1000\n",
            " - 0s - loss: 6.9867 - acc: 0.2375 - val_loss: 11.5613 - val_acc: 0.1500\n",
            "Epoch 698/1000\n",
            " - 0s - loss: 6.5684 - acc: 0.2250 - val_loss: 14.7427 - val_acc: 0.2500\n",
            "Epoch 699/1000\n",
            " - 0s - loss: 6.7776 - acc: 0.2250 - val_loss: 12.3128 - val_acc: 0.2500\n",
            "Epoch 700/1000\n",
            " - 0s - loss: 6.5581 - acc: 0.2875 - val_loss: 11.9436 - val_acc: 0.1500\n",
            "Epoch 701/1000\n",
            " - 0s - loss: 6.5324 - acc: 0.2500 - val_loss: 13.1752 - val_acc: 0.2500\n",
            "Epoch 702/1000\n",
            " - 0s - loss: 6.6218 - acc: 0.2250 - val_loss: 11.5348 - val_acc: 0.1500\n",
            "Epoch 703/1000\n",
            " - 0s - loss: 6.5649 - acc: 0.2625 - val_loss: 12.0419 - val_acc: 0.1500\n",
            "Epoch 704/1000\n",
            " - 0s - loss: 6.8304 - acc: 0.2750 - val_loss: 11.3814 - val_acc: 0.3000\n",
            "Epoch 705/1000\n",
            " - 0s - loss: 6.9687 - acc: 0.2375 - val_loss: 12.9749 - val_acc: 0.2500\n",
            "Epoch 706/1000\n",
            " - 0s - loss: 6.5981 - acc: 0.3000 - val_loss: 10.7919 - val_acc: 0.2500\n",
            "Epoch 707/1000\n",
            " - 0s - loss: 6.5674 - acc: 0.2125 - val_loss: 14.6792 - val_acc: 0.2500\n",
            "Epoch 708/1000\n",
            " - 0s - loss: 6.9032 - acc: 0.2750 - val_loss: 14.9659 - val_acc: 0.2000\n",
            "Epoch 709/1000\n",
            " - 0s - loss: 6.9295 - acc: 0.2875 - val_loss: 11.6660 - val_acc: 0.1500\n",
            "Epoch 710/1000\n",
            " - 0s - loss: 7.1217 - acc: 0.2375 - val_loss: 11.2790 - val_acc: 0.2000\n",
            "Epoch 711/1000\n",
            " - 0s - loss: 6.5416 - acc: 0.2625 - val_loss: 10.4124 - val_acc: 0.2500\n",
            "Epoch 712/1000\n",
            " - 0s - loss: 6.8112 - acc: 0.2000 - val_loss: 11.0196 - val_acc: 0.3000\n",
            "Epoch 713/1000\n",
            " - 0s - loss: 6.5884 - acc: 0.2125 - val_loss: 13.4984 - val_acc: 0.2500\n",
            "Epoch 714/1000\n",
            " - 0s - loss: 6.8179 - acc: 0.2750 - val_loss: 10.1536 - val_acc: 0.3000\n",
            "Epoch 715/1000\n",
            " - 0s - loss: 6.6922 - acc: 0.2250 - val_loss: 10.6950 - val_acc: 0.2500\n",
            "Epoch 716/1000\n",
            " - 0s - loss: 6.8857 - acc: 0.1875 - val_loss: 10.8065 - val_acc: 0.2000\n",
            "Epoch 717/1000\n",
            " - 0s - loss: 6.8670 - acc: 0.2750 - val_loss: 13.2477 - val_acc: 0.2500\n",
            "Epoch 718/1000\n",
            " - 0s - loss: 6.6566 - acc: 0.2500 - val_loss: 13.1138 - val_acc: 0.2500\n",
            "Epoch 719/1000\n",
            " - 0s - loss: 6.6883 - acc: 0.2625 - val_loss: 11.5753 - val_acc: 0.1500\n",
            "Epoch 720/1000\n",
            " - 0s - loss: 6.7013 - acc: 0.2625 - val_loss: 11.1868 - val_acc: 0.1500\n",
            "Epoch 721/1000\n",
            " - 0s - loss: 6.9338 - acc: 0.2125 - val_loss: 11.6909 - val_acc: 0.1500\n",
            "Epoch 722/1000\n",
            " - 0s - loss: 6.5655 - acc: 0.3125 - val_loss: 15.6906 - val_acc: 0.2000\n",
            "Epoch 723/1000\n",
            " - 0s - loss: 7.1664 - acc: 0.2000 - val_loss: 12.3894 - val_acc: 0.2000\n",
            "Epoch 724/1000\n",
            " - 0s - loss: 6.5674 - acc: 0.2375 - val_loss: 16.4414 - val_acc: 0.1500\n",
            "Epoch 725/1000\n",
            " - 0s - loss: 6.9828 - acc: 0.1750 - val_loss: 15.5144 - val_acc: 0.2000\n",
            "Epoch 726/1000\n",
            " - 0s - loss: 6.9183 - acc: 0.2250 - val_loss: 10.6106 - val_acc: 0.1500\n",
            "Epoch 727/1000\n",
            " - 0s - loss: 6.5142 - acc: 0.2375 - val_loss: 13.7083 - val_acc: 0.2500\n",
            "Epoch 728/1000\n",
            " - 0s - loss: 6.6190 - acc: 0.2875 - val_loss: 9.8776 - val_acc: 0.2500\n",
            "Epoch 729/1000\n",
            " - 0s - loss: 6.9878 - acc: 0.2000 - val_loss: 12.1523 - val_acc: 0.2000\n",
            "Epoch 730/1000\n",
            " - 0s - loss: 6.8558 - acc: 0.2500 - val_loss: 15.3017 - val_acc: 0.2000\n",
            "Epoch 731/1000\n",
            " - 0s - loss: 7.0805 - acc: 0.2500 - val_loss: 13.9726 - val_acc: 0.2500\n",
            "Epoch 732/1000\n",
            " - 0s - loss: 6.5280 - acc: 0.1875 - val_loss: 11.7221 - val_acc: 0.1500\n",
            "Epoch 733/1000\n",
            " - 0s - loss: 6.6051 - acc: 0.2750 - val_loss: 12.4043 - val_acc: 0.1500\n",
            "Epoch 734/1000\n",
            " - 0s - loss: 6.5060 - acc: 0.2875 - val_loss: 12.1324 - val_acc: 0.1500\n",
            "Epoch 735/1000\n",
            " - 0s - loss: 6.7407 - acc: 0.2875 - val_loss: 10.7140 - val_acc: 0.1500\n",
            "Epoch 736/1000\n",
            " - 0s - loss: 6.6939 - acc: 0.2250 - val_loss: 12.3482 - val_acc: 0.1500\n",
            "Epoch 737/1000\n",
            " - 0s - loss: 7.1436 - acc: 0.1750 - val_loss: 10.0463 - val_acc: 0.2500\n",
            "Epoch 738/1000\n",
            " - 0s - loss: 6.8635 - acc: 0.2500 - val_loss: 10.6490 - val_acc: 0.2000\n",
            "Epoch 739/1000\n",
            " - 0s - loss: 6.8787 - acc: 0.2125 - val_loss: 10.4400 - val_acc: 0.3000\n",
            "Epoch 740/1000\n",
            " - 0s - loss: 6.4600 - acc: 0.2375 - val_loss: 12.8692 - val_acc: 0.2000\n",
            "Epoch 741/1000\n",
            " - 0s - loss: 6.6752 - acc: 0.2250 - val_loss: 16.3688 - val_acc: 0.2500\n",
            "Epoch 742/1000\n",
            " - 0s - loss: 6.9081 - acc: 0.2500 - val_loss: 13.1494 - val_acc: 0.2500\n",
            "Epoch 743/1000\n",
            " - 0s - loss: 6.6792 - acc: 0.2250 - val_loss: 13.4114 - val_acc: 0.2500\n",
            "Epoch 744/1000\n",
            " - 0s - loss: 6.7042 - acc: 0.2250 - val_loss: 12.5678 - val_acc: 0.2500\n",
            "Epoch 745/1000\n",
            " - 0s - loss: 6.5558 - acc: 0.2250 - val_loss: 11.7786 - val_acc: 0.1500\n",
            "Epoch 746/1000\n",
            " - 0s - loss: 6.8556 - acc: 0.2500 - val_loss: 10.0643 - val_acc: 0.2500\n",
            "Epoch 747/1000\n",
            " - 0s - loss: 6.8609 - acc: 0.2125 - val_loss: 13.5199 - val_acc: 0.2500\n",
            "Epoch 748/1000\n",
            " - 0s - loss: 6.6978 - acc: 0.2500 - val_loss: 12.3719 - val_acc: 0.2500\n",
            "Epoch 749/1000\n",
            " - 0s - loss: 6.5018 - acc: 0.2500 - val_loss: 12.7500 - val_acc: 0.2000\n",
            "Epoch 750/1000\n",
            " - 0s - loss: 7.1887 - acc: 0.2500 - val_loss: 10.4080 - val_acc: 0.3000\n",
            "Epoch 751/1000\n",
            " - 0s - loss: 6.6182 - acc: 0.2500 - val_loss: 13.5549 - val_acc: 0.2500\n",
            "Epoch 752/1000\n",
            " - 0s - loss: 7.0327 - acc: 0.2250 - val_loss: 11.8461 - val_acc: 0.2000\n",
            "Epoch 753/1000\n",
            " - 0s - loss: 6.6867 - acc: 0.2625 - val_loss: 11.6499 - val_acc: 0.2500\n",
            "Epoch 754/1000\n",
            " - 0s - loss: 6.4891 - acc: 0.2625 - val_loss: 14.6031 - val_acc: 0.2000\n",
            "Epoch 755/1000\n",
            " - 0s - loss: 6.5927 - acc: 0.2625 - val_loss: 12.1435 - val_acc: 0.1500\n",
            "Epoch 756/1000\n",
            " - 0s - loss: 6.8306 - acc: 0.2625 - val_loss: 10.9593 - val_acc: 0.1500\n",
            "Epoch 757/1000\n",
            " - 0s - loss: 6.5551 - acc: 0.2500 - val_loss: 16.9261 - val_acc: 0.2500\n",
            "Epoch 758/1000\n",
            " - 0s - loss: 6.5644 - acc: 0.2875 - val_loss: 11.5626 - val_acc: 0.1500\n",
            "Epoch 759/1000\n",
            " - 0s - loss: 6.7421 - acc: 0.2625 - val_loss: 14.3123 - val_acc: 0.2500\n",
            "Epoch 760/1000\n",
            " - 0s - loss: 6.5287 - acc: 0.2875 - val_loss: 10.7849 - val_acc: 0.3000\n",
            "Epoch 761/1000\n",
            " - 0s - loss: 6.6613 - acc: 0.3125 - val_loss: 10.7869 - val_acc: 0.3000\n",
            "Epoch 762/1000\n",
            " - 0s - loss: 6.7882 - acc: 0.2625 - val_loss: 11.7899 - val_acc: 0.2000\n",
            "Epoch 763/1000\n",
            " - 0s - loss: 6.4598 - acc: 0.3000 - val_loss: 10.3108 - val_acc: 0.3000\n",
            "Epoch 764/1000\n",
            " - 0s - loss: 6.5339 - acc: 0.2625 - val_loss: 13.2194 - val_acc: 0.2000\n",
            "Epoch 765/1000\n",
            " - 0s - loss: 6.5281 - acc: 0.3000 - val_loss: 10.8117 - val_acc: 0.2000\n",
            "Epoch 766/1000\n",
            " - 0s - loss: 6.6296 - acc: 0.2125 - val_loss: 10.8456 - val_acc: 0.1500\n",
            "Epoch 767/1000\n",
            " - 0s - loss: 6.6049 - acc: 0.2125 - val_loss: 11.1257 - val_acc: 0.2000\n",
            "Epoch 768/1000\n",
            " - 0s - loss: 6.4920 - acc: 0.3000 - val_loss: 9.9302 - val_acc: 0.2500\n",
            "Epoch 769/1000\n",
            " - 0s - loss: 6.9768 - acc: 0.2125 - val_loss: 11.6313 - val_acc: 0.2500\n",
            "Epoch 770/1000\n",
            " - 0s - loss: 7.0479 - acc: 0.2125 - val_loss: 12.9204 - val_acc: 0.2500\n",
            "Epoch 771/1000\n",
            " - 0s - loss: 6.5713 - acc: 0.3125 - val_loss: 10.9175 - val_acc: 0.1500\n",
            "Epoch 772/1000\n",
            " - 0s - loss: 6.5082 - acc: 0.2000 - val_loss: 10.2398 - val_acc: 0.2000\n",
            "Epoch 773/1000\n",
            " - 0s - loss: 6.4542 - acc: 0.2125 - val_loss: 14.4941 - val_acc: 0.2500\n",
            "Epoch 774/1000\n",
            " - 0s - loss: 6.6673 - acc: 0.2750 - val_loss: 11.7775 - val_acc: 0.2000\n",
            "Epoch 775/1000\n",
            " - 0s - loss: 6.5840 - acc: 0.2375 - val_loss: 12.7562 - val_acc: 0.2500\n",
            "Epoch 776/1000\n",
            " - 0s - loss: 6.6486 - acc: 0.3000 - val_loss: 11.0701 - val_acc: 0.1500\n",
            "Epoch 777/1000\n",
            " - 0s - loss: 6.4680 - acc: 0.2125 - val_loss: 15.8823 - val_acc: 0.2000\n",
            "Epoch 778/1000\n",
            " - 0s - loss: 6.9972 - acc: 0.2625 - val_loss: 13.8964 - val_acc: 0.3000\n",
            "Epoch 779/1000\n",
            " - 0s - loss: 6.6533 - acc: 0.2750 - val_loss: 11.1629 - val_acc: 0.1500\n",
            "Epoch 780/1000\n",
            " - 0s - loss: 6.4535 - acc: 0.2750 - val_loss: 10.2911 - val_acc: 0.3000\n",
            "Epoch 781/1000\n",
            " - 0s - loss: 6.5399 - acc: 0.2500 - val_loss: 11.6339 - val_acc: 0.1500\n",
            "Epoch 782/1000\n",
            " - 0s - loss: 6.3468 - acc: 0.1875 - val_loss: 13.8300 - val_acc: 0.2500\n",
            "Epoch 783/1000\n",
            " - 0s - loss: 6.5001 - acc: 0.2500 - val_loss: 11.4569 - val_acc: 0.1500\n",
            "Epoch 784/1000\n",
            " - 0s - loss: 6.5739 - acc: 0.2500 - val_loss: 10.5825 - val_acc: 0.2500\n",
            "Epoch 785/1000\n",
            " - 0s - loss: 6.4366 - acc: 0.2500 - val_loss: 12.7293 - val_acc: 0.2500\n",
            "Epoch 786/1000\n",
            " - 0s - loss: 6.4423 - acc: 0.2500 - val_loss: 11.7361 - val_acc: 0.1500\n",
            "Epoch 787/1000\n",
            " - 0s - loss: 6.7101 - acc: 0.2000 - val_loss: 9.8787 - val_acc: 0.2000\n",
            "Epoch 788/1000\n",
            " - 0s - loss: 6.5901 - acc: 0.2250 - val_loss: 11.1767 - val_acc: 0.1500\n",
            "Epoch 789/1000\n",
            " - 0s - loss: 6.5595 - acc: 0.3125 - val_loss: 10.1556 - val_acc: 0.3000\n",
            "Epoch 790/1000\n",
            " - 0s - loss: 6.7433 - acc: 0.2250 - val_loss: 12.8669 - val_acc: 0.2000\n",
            "Epoch 791/1000\n",
            " - 0s - loss: 6.6773 - acc: 0.2500 - val_loss: 11.2222 - val_acc: 0.2000\n",
            "Epoch 792/1000\n",
            " - 0s - loss: 6.4304 - acc: 0.2875 - val_loss: 10.3320 - val_acc: 0.3000\n",
            "Epoch 793/1000\n",
            " - 0s - loss: 6.6976 - acc: 0.2250 - val_loss: 11.8880 - val_acc: 0.1500\n",
            "Epoch 794/1000\n",
            " - 0s - loss: 6.6607 - acc: 0.3000 - val_loss: 14.1755 - val_acc: 0.3000\n",
            "Epoch 795/1000\n",
            " - 0s - loss: 6.7781 - acc: 0.2250 - val_loss: 13.2993 - val_acc: 0.2500\n",
            "Epoch 796/1000\n",
            " - 0s - loss: 6.6007 - acc: 0.2375 - val_loss: 11.7507 - val_acc: 0.2000\n",
            "Epoch 797/1000\n",
            " - 0s - loss: 6.5261 - acc: 0.2875 - val_loss: 12.7710 - val_acc: 0.2500\n",
            "Epoch 798/1000\n",
            " - 0s - loss: 6.7357 - acc: 0.2500 - val_loss: 13.0028 - val_acc: 0.2500\n",
            "Epoch 799/1000\n",
            " - 0s - loss: 6.4036 - acc: 0.2500 - val_loss: 13.0862 - val_acc: 0.2500\n",
            "Epoch 800/1000\n",
            " - 0s - loss: 6.5270 - acc: 0.2625 - val_loss: 11.7657 - val_acc: 0.2000\n",
            "Epoch 801/1000\n",
            " - 0s - loss: 6.3914 - acc: 0.2750 - val_loss: 11.7799 - val_acc: 0.1500\n",
            "Epoch 802/1000\n",
            " - 0s - loss: 6.6025 - acc: 0.2125 - val_loss: 10.9429 - val_acc: 0.1500\n",
            "Epoch 803/1000\n",
            " - 0s - loss: 6.3838 - acc: 0.2375 - val_loss: 17.9316 - val_acc: 0.2000\n",
            "Epoch 804/1000\n",
            " - 0s - loss: 6.3362 - acc: 0.1875 - val_loss: 11.1615 - val_acc: 0.3000\n",
            "Epoch 805/1000\n",
            " - 0s - loss: 6.7397 - acc: 0.2250 - val_loss: 10.3093 - val_acc: 0.2500\n",
            "Epoch 806/1000\n",
            " - 0s - loss: 6.5488 - acc: 0.2250 - val_loss: 10.6982 - val_acc: 0.2500\n",
            "Epoch 807/1000\n",
            " - 0s - loss: 6.4292 - acc: 0.2625 - val_loss: 12.8665 - val_acc: 0.2500\n",
            "Epoch 808/1000\n",
            " - 0s - loss: 6.4213 - acc: 0.2500 - val_loss: 12.5177 - val_acc: 0.2000\n",
            "Epoch 809/1000\n",
            " - 0s - loss: 6.6861 - acc: 0.2500 - val_loss: 12.0736 - val_acc: 0.2000\n",
            "Epoch 810/1000\n",
            " - 0s - loss: 6.7760 - acc: 0.2500 - val_loss: 10.5727 - val_acc: 0.1500\n",
            "Epoch 811/1000\n",
            " - 0s - loss: 6.5310 - acc: 0.2625 - val_loss: 12.0818 - val_acc: 0.2000\n",
            "Epoch 812/1000\n",
            " - 0s - loss: 6.5888 - acc: 0.2250 - val_loss: 12.4381 - val_acc: 0.1500\n",
            "Epoch 813/1000\n",
            " - 0s - loss: 6.6502 - acc: 0.1875 - val_loss: 10.9817 - val_acc: 0.1500\n",
            "Epoch 814/1000\n",
            " - 0s - loss: 6.8264 - acc: 0.2625 - val_loss: 11.3158 - val_acc: 0.1500\n",
            "Epoch 815/1000\n",
            " - 0s - loss: 6.4769 - acc: 0.2750 - val_loss: 11.0709 - val_acc: 0.3000\n",
            "Epoch 816/1000\n",
            " - 0s - loss: 6.4381 - acc: 0.3125 - val_loss: 10.2153 - val_acc: 0.3000\n",
            "Epoch 817/1000\n",
            " - 0s - loss: 6.4284 - acc: 0.2250 - val_loss: 12.4673 - val_acc: 0.2500\n",
            "Epoch 818/1000\n",
            " - 0s - loss: 7.0135 - acc: 0.2375 - val_loss: 12.1525 - val_acc: 0.1500\n",
            "Epoch 819/1000\n",
            " - 0s - loss: 6.4939 - acc: 0.2000 - val_loss: 12.2253 - val_acc: 0.1500\n",
            "Epoch 820/1000\n",
            " - 0s - loss: 6.7801 - acc: 0.3250 - val_loss: 11.6435 - val_acc: 0.1500\n",
            "Epoch 821/1000\n",
            " - 0s - loss: 6.4015 - acc: 0.2000 - val_loss: 13.9206 - val_acc: 0.3000\n",
            "Epoch 822/1000\n",
            " - 0s - loss: 6.6634 - acc: 0.2625 - val_loss: 11.2821 - val_acc: 0.1500\n",
            "Epoch 823/1000\n",
            " - 0s - loss: 6.6140 - acc: 0.2375 - val_loss: 11.1724 - val_acc: 0.1500\n",
            "Epoch 824/1000\n",
            " - 0s - loss: 6.3391 - acc: 0.2750 - val_loss: 11.4332 - val_acc: 0.1500\n",
            "Epoch 825/1000\n",
            " - 0s - loss: 6.6151 - acc: 0.2375 - val_loss: 10.4179 - val_acc: 0.2000\n",
            "Epoch 826/1000\n",
            " - 0s - loss: 6.6286 - acc: 0.2500 - val_loss: 15.1259 - val_acc: 0.2000\n",
            "Epoch 827/1000\n",
            " - 0s - loss: 6.5342 - acc: 0.2875 - val_loss: 12.6563 - val_acc: 0.2500\n",
            "Epoch 828/1000\n",
            " - 0s - loss: 6.5104 - acc: 0.2500 - val_loss: 11.3565 - val_acc: 0.2000\n",
            "Epoch 829/1000\n",
            " - 0s - loss: 6.5853 - acc: 0.2875 - val_loss: 10.4109 - val_acc: 0.1500\n",
            "Epoch 830/1000\n",
            " - 0s - loss: 6.3584 - acc: 0.2250 - val_loss: 12.3437 - val_acc: 0.2000\n",
            "Epoch 831/1000\n",
            " - 0s - loss: 6.3606 - acc: 0.2500 - val_loss: 11.3120 - val_acc: 0.2500\n",
            "Epoch 832/1000\n",
            " - 0s - loss: 6.6397 - acc: 0.2500 - val_loss: 10.9706 - val_acc: 0.3000\n",
            "Epoch 833/1000\n",
            " - 0s - loss: 6.6149 - acc: 0.2125 - val_loss: 17.1337 - val_acc: 0.2000\n",
            "Epoch 834/1000\n",
            " - 0s - loss: 6.6521 - acc: 0.2250 - val_loss: 10.3916 - val_acc: 0.2500\n",
            "Epoch 835/1000\n",
            " - 0s - loss: 6.6096 - acc: 0.2375 - val_loss: 14.4991 - val_acc: 0.2500\n",
            "Epoch 836/1000\n",
            " - 0s - loss: 6.4737 - acc: 0.2000 - val_loss: 9.8422 - val_acc: 0.2000\n",
            "Epoch 837/1000\n",
            " - 0s - loss: 6.7281 - acc: 0.3000 - val_loss: 14.0546 - val_acc: 0.2500\n",
            "Epoch 838/1000\n",
            " - 0s - loss: 6.7341 - acc: 0.2250 - val_loss: 15.7476 - val_acc: 0.2500\n",
            "Epoch 839/1000\n",
            " - 0s - loss: 6.9370 - acc: 0.1875 - val_loss: 17.6754 - val_acc: 0.2000\n",
            "Epoch 840/1000\n",
            " - 0s - loss: 7.0702 - acc: 0.2750 - val_loss: 13.8094 - val_acc: 0.2500\n",
            "Epoch 841/1000\n",
            " - 0s - loss: 6.7992 - acc: 0.2250 - val_loss: 17.4429 - val_acc: 0.2000\n",
            "Epoch 842/1000\n",
            " - 0s - loss: 6.7613 - acc: 0.2750 - val_loss: 11.5615 - val_acc: 0.2000\n",
            "Epoch 843/1000\n",
            " - 0s - loss: 6.3247 - acc: 0.2625 - val_loss: 11.4506 - val_acc: 0.2500\n",
            "Epoch 844/1000\n",
            " - 0s - loss: 6.3399 - acc: 0.3000 - val_loss: 10.5696 - val_acc: 0.1500\n",
            "Epoch 845/1000\n",
            " - 0s - loss: 6.3460 - acc: 0.2375 - val_loss: 11.9496 - val_acc: 0.2000\n",
            "Epoch 846/1000\n",
            " - 0s - loss: 6.4423 - acc: 0.3125 - val_loss: 9.5758 - val_acc: 0.3000\n",
            "Epoch 847/1000\n",
            " - 0s - loss: 6.4327 - acc: 0.2250 - val_loss: 13.4036 - val_acc: 0.2500\n",
            "Epoch 848/1000\n",
            " - 0s - loss: 6.5731 - acc: 0.2500 - val_loss: 9.4133 - val_acc: 0.3000\n",
            "Epoch 849/1000\n",
            " - 0s - loss: 7.0158 - acc: 0.2625 - val_loss: 10.0400 - val_acc: 0.2500\n",
            "Epoch 850/1000\n",
            " - 0s - loss: 6.6798 - acc: 0.2375 - val_loss: 11.6934 - val_acc: 0.2000\n",
            "Epoch 851/1000\n",
            " - 0s - loss: 6.5841 - acc: 0.2250 - val_loss: 11.8611 - val_acc: 0.1500\n",
            "Epoch 852/1000\n",
            " - 0s - loss: 6.3400 - acc: 0.2875 - val_loss: 10.4835 - val_acc: 0.2000\n",
            "Epoch 853/1000\n",
            " - 0s - loss: 6.7534 - acc: 0.2250 - val_loss: 10.3554 - val_acc: 0.2000\n",
            "Epoch 854/1000\n",
            " - 0s - loss: 6.4665 - acc: 0.2875 - val_loss: 10.7519 - val_acc: 0.2000\n",
            "Epoch 855/1000\n",
            " - 0s - loss: 6.5293 - acc: 0.2625 - val_loss: 9.4433 - val_acc: 0.2500\n",
            "Epoch 856/1000\n",
            " - 0s - loss: 6.7413 - acc: 0.2000 - val_loss: 9.6705 - val_acc: 0.3000\n",
            "Epoch 857/1000\n",
            " - 0s - loss: 6.4126 - acc: 0.2125 - val_loss: 12.4779 - val_acc: 0.2500\n",
            "Epoch 858/1000\n",
            " - 0s - loss: 6.5407 - acc: 0.2250 - val_loss: 11.4087 - val_acc: 0.2500\n",
            "Epoch 859/1000\n",
            " - 0s - loss: 6.8414 - acc: 0.1875 - val_loss: 12.8799 - val_acc: 0.2000\n",
            "Epoch 860/1000\n",
            " - 0s - loss: 6.5745 - acc: 0.2375 - val_loss: 10.8786 - val_acc: 0.1500\n",
            "Epoch 861/1000\n",
            " - 0s - loss: 6.2015 - acc: 0.2000 - val_loss: 13.5241 - val_acc: 0.2500\n",
            "Epoch 862/1000\n",
            " - 0s - loss: 6.3841 - acc: 0.2500 - val_loss: 10.1239 - val_acc: 0.3000\n",
            "Epoch 863/1000\n",
            " - 0s - loss: 6.3431 - acc: 0.2000 - val_loss: 10.3589 - val_acc: 0.2000\n",
            "Epoch 864/1000\n",
            " - 0s - loss: 6.5290 - acc: 0.2375 - val_loss: 10.5483 - val_acc: 0.2000\n",
            "Epoch 865/1000\n",
            " - 0s - loss: 6.3328 - acc: 0.2500 - val_loss: 10.2121 - val_acc: 0.2000\n",
            "Epoch 866/1000\n",
            " - 0s - loss: 6.6448 - acc: 0.2000 - val_loss: 11.0430 - val_acc: 0.2000\n",
            "Epoch 867/1000\n",
            " - 0s - loss: 6.3309 - acc: 0.2500 - val_loss: 10.9903 - val_acc: 0.2000\n",
            "Epoch 868/1000\n",
            " - 0s - loss: 6.3893 - acc: 0.2000 - val_loss: 14.2289 - val_acc: 0.2500\n",
            "Epoch 869/1000\n",
            " - 0s - loss: 6.4680 - acc: 0.2625 - val_loss: 12.3219 - val_acc: 0.2500\n",
            "Epoch 870/1000\n",
            " - 0s - loss: 6.3749 - acc: 0.2375 - val_loss: 10.6587 - val_acc: 0.2000\n",
            "Epoch 871/1000\n",
            " - 0s - loss: 6.2545 - acc: 0.2375 - val_loss: 12.0072 - val_acc: 0.2000\n",
            "Epoch 872/1000\n",
            " - 0s - loss: 6.5064 - acc: 0.2375 - val_loss: 9.9984 - val_acc: 0.2500\n",
            "Epoch 873/1000\n",
            " - 0s - loss: 6.1549 - acc: 0.2875 - val_loss: 11.2110 - val_acc: 0.1500\n",
            "Epoch 874/1000\n",
            " - 0s - loss: 6.4452 - acc: 0.2750 - val_loss: 11.8735 - val_acc: 0.2500\n",
            "Epoch 875/1000\n",
            " - 0s - loss: 6.5004 - acc: 0.2625 - val_loss: 13.6641 - val_acc: 0.2500\n",
            "Epoch 876/1000\n",
            " - 0s - loss: 6.3982 - acc: 0.3125 - val_loss: 12.0847 - val_acc: 0.2500\n",
            "Epoch 877/1000\n",
            " - 0s - loss: 6.3704 - acc: 0.2875 - val_loss: 10.8174 - val_acc: 0.1500\n",
            "Epoch 878/1000\n",
            " - 0s - loss: 6.3874 - acc: 0.2375 - val_loss: 13.5740 - val_acc: 0.2500\n",
            "Epoch 879/1000\n",
            " - 0s - loss: 6.4016 - acc: 0.2500 - val_loss: 10.9122 - val_acc: 0.1500\n",
            "Epoch 880/1000\n",
            " - 0s - loss: 6.5434 - acc: 0.2750 - val_loss: 9.5618 - val_acc: 0.3500\n",
            "Epoch 881/1000\n",
            " - 0s - loss: 6.3657 - acc: 0.2375 - val_loss: 12.7735 - val_acc: 0.2500\n",
            "Epoch 882/1000\n",
            " - 0s - loss: 6.3196 - acc: 0.2375 - val_loss: 12.0213 - val_acc: 0.2000\n",
            "Epoch 883/1000\n",
            " - 0s - loss: 6.4529 - acc: 0.2625 - val_loss: 11.3091 - val_acc: 0.1500\n",
            "Epoch 884/1000\n",
            " - 0s - loss: 6.2731 - acc: 0.2750 - val_loss: 11.5794 - val_acc: 0.1500\n",
            "Epoch 885/1000\n",
            " - 0s - loss: 6.2880 - acc: 0.3000 - val_loss: 11.4569 - val_acc: 0.1500\n",
            "Epoch 886/1000\n",
            " - 0s - loss: 6.2569 - acc: 0.2375 - val_loss: 13.0059 - val_acc: 0.2000\n",
            "Epoch 887/1000\n",
            " - 0s - loss: 6.3378 - acc: 0.2625 - val_loss: 10.3200 - val_acc: 0.2000\n",
            "Epoch 888/1000\n",
            " - 0s - loss: 6.3953 - acc: 0.2375 - val_loss: 10.2493 - val_acc: 0.2500\n",
            "Epoch 889/1000\n",
            " - 0s - loss: 6.2978 - acc: 0.2250 - val_loss: 10.2700 - val_acc: 0.2500\n",
            "Epoch 890/1000\n",
            " - 0s - loss: 6.3658 - acc: 0.2375 - val_loss: 11.5148 - val_acc: 0.1500\n",
            "Epoch 891/1000\n",
            " - 0s - loss: 6.4303 - acc: 0.2875 - val_loss: 11.5633 - val_acc: 0.1500\n",
            "Epoch 892/1000\n",
            " - 0s - loss: 6.2322 - acc: 0.3125 - val_loss: 10.6793 - val_acc: 0.2500\n",
            "Epoch 893/1000\n",
            " - 0s - loss: 6.5833 - acc: 0.2125 - val_loss: 12.7378 - val_acc: 0.2000\n",
            "Epoch 894/1000\n",
            " - 0s - loss: 6.4240 - acc: 0.1500 - val_loss: 10.5403 - val_acc: 0.1500\n",
            "Epoch 895/1000\n",
            " - 0s - loss: 6.3854 - acc: 0.3000 - val_loss: 11.4421 - val_acc: 0.2500\n",
            "Epoch 896/1000\n",
            " - 0s - loss: 6.2671 - acc: 0.2250 - val_loss: 16.1740 - val_acc: 0.2000\n",
            "Epoch 897/1000\n",
            " - 0s - loss: 6.1933 - acc: 0.2375 - val_loss: 9.9619 - val_acc: 0.2000\n",
            "Epoch 898/1000\n",
            " - 0s - loss: 6.8552 - acc: 0.1750 - val_loss: 10.9262 - val_acc: 0.2000\n",
            "Epoch 899/1000\n",
            " - 0s - loss: 6.5379 - acc: 0.2875 - val_loss: 10.5997 - val_acc: 0.1500\n",
            "Epoch 900/1000\n",
            " - 0s - loss: 6.3670 - acc: 0.3000 - val_loss: 10.6921 - val_acc: 0.2000\n",
            "Epoch 901/1000\n",
            " - 0s - loss: 6.2743 - acc: 0.2875 - val_loss: 10.2145 - val_acc: 0.2000\n",
            "Epoch 902/1000\n",
            " - 0s - loss: 6.2877 - acc: 0.2500 - val_loss: 12.1792 - val_acc: 0.2000\n",
            "Epoch 903/1000\n",
            " - 0s - loss: 6.6805 - acc: 0.2375 - val_loss: 11.7202 - val_acc: 0.2500\n",
            "Epoch 904/1000\n",
            " - 0s - loss: 6.3095 - acc: 0.2500 - val_loss: 13.5196 - val_acc: 0.2500\n",
            "Epoch 905/1000\n",
            " - 0s - loss: 6.4214 - acc: 0.2750 - val_loss: 11.9378 - val_acc: 0.1500\n",
            "Epoch 906/1000\n",
            " - 0s - loss: 6.2105 - acc: 0.2500 - val_loss: 12.7776 - val_acc: 0.2500\n",
            "Epoch 907/1000\n",
            " - 0s - loss: 6.1787 - acc: 0.2250 - val_loss: 10.6397 - val_acc: 0.3000\n",
            "Epoch 908/1000\n",
            " - 0s - loss: 6.3117 - acc: 0.2125 - val_loss: 11.0089 - val_acc: 0.2000\n",
            "Epoch 909/1000\n",
            " - 0s - loss: 6.5680 - acc: 0.2500 - val_loss: 10.4057 - val_acc: 0.2500\n",
            "Epoch 910/1000\n",
            " - 0s - loss: 6.6935 - acc: 0.2375 - val_loss: 12.0205 - val_acc: 0.2500\n",
            "Epoch 911/1000\n",
            " - 0s - loss: 6.2343 - acc: 0.2375 - val_loss: 11.8320 - val_acc: 0.2500\n",
            "Epoch 912/1000\n",
            " - 0s - loss: 6.2548 - acc: 0.2250 - val_loss: 9.8989 - val_acc: 0.2500\n",
            "Epoch 913/1000\n",
            " - 0s - loss: 6.2967 - acc: 0.2375 - val_loss: 9.3450 - val_acc: 0.3000\n",
            "Epoch 914/1000\n",
            " - 0s - loss: 6.4703 - acc: 0.2250 - val_loss: 11.0963 - val_acc: 0.1500\n",
            "Epoch 915/1000\n",
            " - 0s - loss: 6.2340 - acc: 0.2750 - val_loss: 11.9320 - val_acc: 0.2500\n",
            "Epoch 916/1000\n",
            " - 0s - loss: 6.5792 - acc: 0.2500 - val_loss: 13.9586 - val_acc: 0.3000\n",
            "Epoch 917/1000\n",
            " - 0s - loss: 7.0536 - acc: 0.2250 - val_loss: 12.9172 - val_acc: 0.2500\n",
            "Epoch 918/1000\n",
            " - 0s - loss: 6.8319 - acc: 0.2125 - val_loss: 10.8076 - val_acc: 0.2000\n",
            "Epoch 919/1000\n",
            " - 0s - loss: 6.3800 - acc: 0.2625 - val_loss: 11.1479 - val_acc: 0.2000\n",
            "Epoch 920/1000\n",
            " - 0s - loss: 6.1840 - acc: 0.2875 - val_loss: 10.9408 - val_acc: 0.2000\n",
            "Epoch 921/1000\n",
            " - 0s - loss: 6.2190 - acc: 0.3000 - val_loss: 10.6707 - val_acc: 0.2000\n",
            "Epoch 922/1000\n",
            " - 0s - loss: 6.3234 - acc: 0.2250 - val_loss: 15.7638 - val_acc: 0.2000\n",
            "Epoch 923/1000\n",
            " - 0s - loss: 6.3886 - acc: 0.2125 - val_loss: 13.6672 - val_acc: 0.2500\n",
            "Epoch 924/1000\n",
            " - 0s - loss: 6.4141 - acc: 0.2750 - val_loss: 17.4924 - val_acc: 0.2000\n",
            "Epoch 925/1000\n",
            " - 0s - loss: 6.5525 - acc: 0.2250 - val_loss: 12.6341 - val_acc: 0.2500\n",
            "Epoch 926/1000\n",
            " - 0s - loss: 6.4313 - acc: 0.2750 - val_loss: 9.8394 - val_acc: 0.2500\n",
            "Epoch 927/1000\n",
            " - 0s - loss: 6.6069 - acc: 0.2500 - val_loss: 11.5799 - val_acc: 0.2000\n",
            "Epoch 928/1000\n",
            " - 0s - loss: 6.2393 - acc: 0.2250 - val_loss: 12.0311 - val_acc: 0.2000\n",
            "Epoch 929/1000\n",
            " - 0s - loss: 6.3232 - acc: 0.3000 - val_loss: 9.8701 - val_acc: 0.2500\n",
            "Epoch 930/1000\n",
            " - 0s - loss: 6.3949 - acc: 0.2625 - val_loss: 10.7320 - val_acc: 0.2000\n",
            "Epoch 931/1000\n",
            " - 0s - loss: 6.2345 - acc: 0.2375 - val_loss: 12.4766 - val_acc: 0.2500\n",
            "Epoch 932/1000\n",
            " - 0s - loss: 6.5036 - acc: 0.2250 - val_loss: 11.1873 - val_acc: 0.2500\n",
            "Epoch 933/1000\n",
            " - 0s - loss: 6.2927 - acc: 0.2250 - val_loss: 10.9184 - val_acc: 0.2000\n",
            "Epoch 934/1000\n",
            " - 0s - loss: 6.3381 - acc: 0.2125 - val_loss: 12.1025 - val_acc: 0.2000\n",
            "Epoch 935/1000\n",
            " - 0s - loss: 6.4749 - acc: 0.2500 - val_loss: 12.4336 - val_acc: 0.2500\n",
            "Epoch 936/1000\n",
            " - 0s - loss: 6.2423 - acc: 0.2125 - val_loss: 11.7055 - val_acc: 0.2000\n",
            "Epoch 937/1000\n",
            " - 0s - loss: 6.3024 - acc: 0.2750 - val_loss: 11.4133 - val_acc: 0.2000\n",
            "Epoch 938/1000\n",
            " - 0s - loss: 6.2477 - acc: 0.2500 - val_loss: 12.8183 - val_acc: 0.2500\n",
            "Epoch 939/1000\n",
            " - 0s - loss: 6.4663 - acc: 0.3125 - val_loss: 10.4355 - val_acc: 0.2000\n",
            "Epoch 940/1000\n",
            " - 0s - loss: 6.3970 - acc: 0.2375 - val_loss: 10.3573 - val_acc: 0.1500\n",
            "Epoch 941/1000\n",
            " - 0s - loss: 6.1981 - acc: 0.2875 - val_loss: 9.9973 - val_acc: 0.2500\n",
            "Epoch 942/1000\n",
            " - 0s - loss: 6.2865 - acc: 0.2500 - val_loss: 10.0773 - val_acc: 0.2500\n",
            "Epoch 943/1000\n",
            " - 0s - loss: 6.4266 - acc: 0.2625 - val_loss: 10.3235 - val_acc: 0.2500\n",
            "Epoch 944/1000\n",
            " - 0s - loss: 6.5687 - acc: 0.2375 - val_loss: 12.8276 - val_acc: 0.2500\n",
            "Epoch 945/1000\n",
            " - 0s - loss: 6.2403 - acc: 0.2500 - val_loss: 14.3201 - val_acc: 0.2000\n",
            "Epoch 946/1000\n",
            " - 0s - loss: 6.3455 - acc: 0.2750 - val_loss: 12.1096 - val_acc: 0.2500\n",
            "Epoch 947/1000\n",
            " - 0s - loss: 6.3358 - acc: 0.2875 - val_loss: 11.7847 - val_acc: 0.2000\n",
            "Epoch 948/1000\n",
            " - 0s - loss: 6.1484 - acc: 0.2750 - val_loss: 10.4411 - val_acc: 0.1500\n",
            "Epoch 949/1000\n",
            " - 0s - loss: 6.2256 - acc: 0.2375 - val_loss: 11.7792 - val_acc: 0.2500\n",
            "Epoch 950/1000\n",
            " - 0s - loss: 6.2498 - acc: 0.2625 - val_loss: 14.3065 - val_acc: 0.2000\n",
            "Epoch 951/1000\n",
            " - 0s - loss: 6.1761 - acc: 0.2625 - val_loss: 9.8750 - val_acc: 0.2000\n",
            "Epoch 952/1000\n",
            " - 0s - loss: 6.2418 - acc: 0.2375 - val_loss: 11.3747 - val_acc: 0.1500\n",
            "Epoch 953/1000\n",
            " - 0s - loss: 6.2120 - acc: 0.3000 - val_loss: 10.9862 - val_acc: 0.1500\n",
            "Epoch 954/1000\n",
            " - 0s - loss: 6.2951 - acc: 0.2000 - val_loss: 13.8301 - val_acc: 0.2000\n",
            "Epoch 955/1000\n",
            " - 0s - loss: 6.3747 - acc: 0.2500 - val_loss: 11.0019 - val_acc: 0.2500\n",
            "Epoch 956/1000\n",
            " - 0s - loss: 6.3531 - acc: 0.2750 - val_loss: 10.1050 - val_acc: 0.2500\n",
            "Epoch 957/1000\n",
            " - 0s - loss: 6.2262 - acc: 0.2750 - val_loss: 9.5983 - val_acc: 0.2500\n",
            "Epoch 958/1000\n",
            " - 0s - loss: 6.0658 - acc: 0.3125 - val_loss: 11.5268 - val_acc: 0.2500\n",
            "Epoch 959/1000\n",
            " - 0s - loss: 6.2553 - acc: 0.2500 - val_loss: 11.5068 - val_acc: 0.2500\n",
            "Epoch 960/1000\n",
            " - 0s - loss: 6.2843 - acc: 0.2500 - val_loss: 10.4513 - val_acc: 0.2000\n",
            "Epoch 961/1000\n",
            " - 0s - loss: 6.1050 - acc: 0.1875 - val_loss: 13.2828 - val_acc: 0.2500\n",
            "Epoch 962/1000\n",
            " - 0s - loss: 6.4533 - acc: 0.2500 - val_loss: 10.2909 - val_acc: 0.1500\n",
            "Epoch 963/1000\n",
            " - 0s - loss: 6.1678 - acc: 0.2750 - val_loss: 14.5606 - val_acc: 0.2000\n",
            "Epoch 964/1000\n",
            " - 0s - loss: 6.1998 - acc: 0.2375 - val_loss: 13.0242 - val_acc: 0.2500\n",
            "Epoch 965/1000\n",
            " - 0s - loss: 6.3295 - acc: 0.2125 - val_loss: 12.2867 - val_acc: 0.2500\n",
            "Epoch 966/1000\n",
            " - 0s - loss: 6.4220 - acc: 0.2375 - val_loss: 11.7621 - val_acc: 0.2000\n",
            "Epoch 967/1000\n",
            " - 0s - loss: 6.2036 - acc: 0.2500 - val_loss: 12.9916 - val_acc: 0.2500\n",
            "Epoch 968/1000\n",
            " - 0s - loss: 6.6597 - acc: 0.2125 - val_loss: 13.3978 - val_acc: 0.2500\n",
            "Epoch 969/1000\n",
            " - 0s - loss: 6.3840 - acc: 0.2500 - val_loss: 12.0693 - val_acc: 0.2500\n",
            "Epoch 970/1000\n",
            " - 0s - loss: 6.4884 - acc: 0.2375 - val_loss: 14.4450 - val_acc: 0.2000\n",
            "Epoch 971/1000\n",
            " - 0s - loss: 6.4739 - acc: 0.2875 - val_loss: 11.3896 - val_acc: 0.2500\n",
            "Epoch 972/1000\n",
            " - 0s - loss: 6.2443 - acc: 0.2250 - val_loss: 12.5910 - val_acc: 0.2500\n",
            "Epoch 973/1000\n",
            " - 0s - loss: 6.4951 - acc: 0.2625 - val_loss: 11.2135 - val_acc: 0.2000\n",
            "Epoch 974/1000\n",
            " - 0s - loss: 6.2174 - acc: 0.2625 - val_loss: 11.7503 - val_acc: 0.2500\n",
            "Epoch 975/1000\n",
            " - 0s - loss: 6.2420 - acc: 0.2250 - val_loss: 12.6566 - val_acc: 0.2500\n",
            "Epoch 976/1000\n",
            " - 0s - loss: 6.3310 - acc: 0.3000 - val_loss: 9.5961 - val_acc: 0.2500\n",
            "Epoch 977/1000\n",
            " - 0s - loss: 6.5735 - acc: 0.2000 - val_loss: 11.7044 - val_acc: 0.2500\n",
            "Epoch 978/1000\n",
            " - 0s - loss: 6.2395 - acc: 0.2500 - val_loss: 11.6492 - val_acc: 0.2500\n",
            "Epoch 979/1000\n",
            " - 0s - loss: 6.2228 - acc: 0.2875 - val_loss: 11.1771 - val_acc: 0.1500\n",
            "Epoch 980/1000\n",
            " - 0s - loss: 6.2856 - acc: 0.2625 - val_loss: 11.9694 - val_acc: 0.2500\n",
            "Epoch 981/1000\n",
            " - 0s - loss: 6.0622 - acc: 0.2250 - val_loss: 15.9754 - val_acc: 0.2000\n",
            "Epoch 982/1000\n",
            " - 0s - loss: 6.3092 - acc: 0.2625 - val_loss: 11.3162 - val_acc: 0.2000\n",
            "Epoch 983/1000\n",
            " - 0s - loss: 6.5575 - acc: 0.3000 - val_loss: 9.9320 - val_acc: 0.1500\n",
            "Epoch 984/1000\n",
            " - 0s - loss: 6.1837 - acc: 0.3000 - val_loss: 10.5051 - val_acc: 0.1500\n",
            "Epoch 985/1000\n",
            " - 0s - loss: 6.3850 - acc: 0.2250 - val_loss: 14.3663 - val_acc: 0.2000\n",
            "Epoch 986/1000\n",
            " - 0s - loss: 6.2813 - acc: 0.2500 - val_loss: 11.1346 - val_acc: 0.1500\n",
            "Epoch 987/1000\n",
            " - 0s - loss: 6.2525 - acc: 0.2750 - val_loss: 10.1074 - val_acc: 0.2500\n",
            "Epoch 988/1000\n",
            " - 0s - loss: 6.5865 - acc: 0.2000 - val_loss: 11.4155 - val_acc: 0.1500\n",
            "Epoch 989/1000\n",
            " - 0s - loss: 6.0753 - acc: 0.3000 - val_loss: 9.3943 - val_acc: 0.2500\n",
            "Epoch 990/1000\n",
            " - 0s - loss: 6.7032 - acc: 0.2375 - val_loss: 9.9103 - val_acc: 0.2500\n",
            "Epoch 991/1000\n",
            " - 0s - loss: 6.2271 - acc: 0.2250 - val_loss: 14.5757 - val_acc: 0.2000\n",
            "Epoch 992/1000\n",
            " - 0s - loss: 6.3504 - acc: 0.2500 - val_loss: 11.1014 - val_acc: 0.1500\n",
            "Epoch 993/1000\n",
            " - 0s - loss: 6.2003 - acc: 0.2375 - val_loss: 11.5785 - val_acc: 0.2000\n",
            "Epoch 994/1000\n",
            " - 0s - loss: 6.0368 - acc: 0.2500 - val_loss: 11.8189 - val_acc: 0.2500\n",
            "Epoch 995/1000\n",
            " - 0s - loss: 6.5215 - acc: 0.2625 - val_loss: 15.2501 - val_acc: 0.2000\n",
            "Epoch 996/1000\n",
            " - 0s - loss: 6.3542 - acc: 0.2000 - val_loss: 11.3220 - val_acc: 0.1500\n",
            "Epoch 997/1000\n",
            " - 0s - loss: 6.0791 - acc: 0.3375 - val_loss: 11.8628 - val_acc: 0.2500\n",
            "Epoch 998/1000\n",
            " - 0s - loss: 6.0848 - acc: 0.2750 - val_loss: 12.2524 - val_acc: 0.2500\n",
            "Epoch 999/1000\n",
            " - 0s - loss: 6.3883 - acc: 0.2875 - val_loss: 11.0481 - val_acc: 0.1500\n",
            "Epoch 1000/1000\n",
            " - 0s - loss: 6.1958 - acc: 0.2500 - val_loss: 10.7044 - val_acc: 0.1500\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 11\n",
            "Trainable params: 11\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV9nQ3FWrzZN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "277a927d-dd9b-4ea0-f23c-cd425fb4e3e3"
      },
      "source": [
        "# evaluate the keras model\n",
        "loss, accuracy = model.evaluate(X, Y)\n",
        "print(\"\\nLoss: %.3f, Accuracy: %.2f%%\" % (loss, accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 0s 75us/step\n",
            "\n",
            "Loss: 6.849, Accuracy: 25.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3o4SJper2ON",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9475d02a-14c8-45bb-ece0-db74ac70c302"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['acc']\n",
        "loss = history_dict['loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAftElEQVR4nO3de5QdZZ3u8e+TCwmQQEjSckkgHSFH\n7aiE2CvAiR4QUQFHUcERaC6DzAoyqHgUj0GcM4pmDTIqAgczROWi6QFRdMwwDBkIzHE4aqCDIZCE\nTCIQ6BBIEyUEkEsnv/NHvV3sJH3Z3em9d3fX81mr1q56663ab6WSPLveuikiMDMzAxhW6waYmdnA\n4VAwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8GshKThkl6UdEh/1u1DO74p6cb+Xq9ZT0bUugFm\nu0PSiyWTewGvAtvS9PkR0dyb9UXENmBMf9c1GywcCjaoRUT+n7KkJ4C/joi7u6ovaUREtFejbWaD\nkbuPbEhL3TA/lXSzpK3AmZKOlvQ7Sc9L2ijpakkjU/0RkkJSfZpemOb/m6Stkn4raWpv66b5J0r6\nL0lbJF0j6f9J+qsyt+NjklamNt8j6S0l874i6WlJL0h6VNKxqfwoSQ+m8mcl/UM//JHaEOdQsCL4\nGPBPwL7AT4F24CJgIjAbOAE4v5vlzwD+FhgPPAl8o7d1Jb0JuBX4Uvrex4FZ5TRe0tuAnwCfBeqA\nu4FFkkZKmp7aPjMi9gFOTN8LcA3wD6n8MODn5XyfFZtDwYrgvoj4l4jYHhF/jogHImJpRLRHxGPA\nAuCYbpb/eUS0RMTrQDMwow91/wJYHhG/SvOuBJ4rs/2nAYsi4p607OVkAXckWcCNBqanrrHH0zYB\nvA5MkzQhIrZGxNIyv88KzKFgRfBU6YSkt0r6V0nPSHoBuIzs13tXnikZf5nuTy53Vfeg0nZE9iTK\n1jLa3rHs+pJlt6dlJ0XEGuCLZNuwKXWTHZCqngs0AGsk3S/ppDK/zwrMoWBFsPOjgK8DHgEOS10r\n/xtQhduwEZjcMSFJwKQyl30amFKy7LC0rg0AEbEwImYDU4HhwN+n8jURcRrwJuA7wG2SRu/+pthQ\n5lCwIhoLbAFeSv313Z1P6C+3AzMlfVjSCLJzGnVlLnsr8BFJx6YT4l8CtgJLJb1N0nsljQL+nIbt\nAJLOkjQxHVlsIQvH7f27WTbUOBSsiL4InEP2H+t1ZCefKyoingU+CXwX2AwcCvye7L6KnpZdSdbe\n+UAb2Ynxj6TzC6OAK8jOTzwD7AdcmhY9CVidrrr6NvDJiHitHzfLhiD5JTtm1SdpOFm30KkR8Z+1\nbo9ZBx8pmFWJpBMkjUtdPX9LdnXQ/TVultkOHApm1fNu4DGyLqAPAh+LiB67j8yqyd1HZmaW85GC\nmZnlBvUD8SZOnBj19fW1boaZ2aCybNmy5yKi00uiB3Uo1NfX09LSUutmmJkNKpLWdzXP3UdmZpZz\nKJiZWc6hYGZmuUF9TsHMBp7XX3+d1tZWXnnllVo3pfBGjx7N5MmTGTlyZNnLOBTMrF+1trYyduxY\n6uvryR4Ga7UQEWzevJnW1lamTp3a8wJJ4bqPmpuhvh6GDcs+m3v1Wncz68krr7zChAkTHAg1JokJ\nEyb0+oitUEcKzc0wZw68/HI2vX59Ng3Q1FS7dpkNNQ6EgaEv+6FQRwqXXvpGIHR4+eWs3MzMChYK\nTz7Zu3IzG3w2b97MjBkzmDFjBgcccACTJk3Kp197rbzXSZx77rmsWbOm2zrXXnstzf3U//zud7+b\n5cuX98u6dlehuo8OOSTrMuqs3Mxqo7k5O1p/8sns3+K8ebvXnTthwoT8P9ivfe1rjBkzhosvvniH\nOhFBRDBsWOe/i2+44YYev+fCCy/seyMHsEIdKcybB3vttWPZXntl5WZWfR3n+davh4g3zvNV4gKQ\ndevW0dDQQFNTE9OnT2fjxo3MmTOHxsZGpk+fzmWXXZbX7fjl3t7ezrhx45g7dy6HH344Rx99NJs2\nbQLgq1/9Kt/73vfy+nPnzmXWrFm85S1v4Te/+Q0AL730EqeccgoNDQ2ceuqpNDY29nhEsHDhQt7x\njnfw9re/na985SsAtLe3c9ZZZ+XlV199NQBXXnklDQ0NvPOd7+TMM8/slz+nQh0pdPz66M9fJWbW\nd92d56vEv8tHH32UH//4xzQ2NgJw+eWXM378eNrb23nve9/LqaeeSkNDww7LbNmyhWOOOYbLL7+c\nL3zhC1x//fXMnTt3l3VHBPfffz+LFi3isssu48477+Saa67hgAMO4LbbbuOhhx5i5syZ3bavtbWV\nr371q7S0tLDvvvty/PHHc/vtt1NXV8dzzz3Hww8/DMDzzz8PwBVXXMH69evZY4898rLdVagjBcj+\noj3xBGzfnn06EMxqp9rn+Q499NA8EABuvvlmZs6cycyZM1m9ejWrVq3aZZk999yTE088EYB3vetd\nPPHEE52u++Mf//gude677z5OO+00AA4//HCmT5/ebfuWLl3Kcccdx8SJExk5ciRnnHEGv/71rzns\nsMNYs2YNn/vc51i8eDH77rsvANOnT+fMM8+kubm5VzeodadwoWBmA0dX5/MqdZ5v7733zsfXrl3L\nVVddxT333MOKFSs44YQTOr2mf4899sjHhw8fTnt7e6frHjVqVI91+mrChAmsWLGC97znPVx77bWc\nf/75ACxevJhPf/rTPPDAA8yaNYtt27bt9ndVLBQkjZZ0v6SHJK2U9PVUfqOkxyUtT8OMVC5JV0ta\nJ2mFpO6Ps8xs0Kvleb4XXniBsWPHss8++7Bx40YWL17c798xe/Zsbr31VgAefvjhTo9ESh155JHc\ne++9bN68mfb2dm655RaOOeYY2traiAg+8YlPcNlll/Hggw+ybds2WltbOe6447jiiit47rnneHnn\nvrg+qOQ5hVeB4yLiRUkjgfsk/Vua96WI+PlO9U8EpqXhSGB++jSzIaqW5/lmzpxJQ0MDb33rW5ky\nZQqzZ8/u9+/47Gc/y9lnn01DQ0M+dHT9dGby5Ml84xvf4NhjjyUi+PCHP8yHPvQhHnzwQc477zwi\nAkl861vfor29nTPOOIOtW7eyfft2Lr74YsaOHbvbba7KO5ol7QXcB1yQhtt3DgVJ1wH/ERE3p+k1\nwLERsbGr9TY2NoZfsmM2sKxevZq3ve1ttW7GgNDe3k57ezujR49m7dq1fOADH2Dt2rWMGFG9a3w6\n2x+SlkVEY2f1K3pOQdJwScuBTcBdEbE0zZqXuoiulDQqlU0CnipZvDWV7bzOOZJaJLW0tbVVsvlm\nZrvlxRdfZPbs2Rx++OGccsopXHfddVUNhL6oaOsiYhswQ9I44JeS3g5cAjwD7AEsAL4MXNb1WnZZ\n54K0HI2NjZU/zDEz66Nx48axbNmyWjejV6py9VFEPA/cC5wQERsj8ypwAzArVdsAHFyy2ORUZmaD\nTDW6pa1nfdkPlbz6qC4dISBpT+D9wKOSDkxlAj4KPJIWWQScna5COgrY0t35BDMbmEaPHs3mzZsd\nDDXW8T6F0aNH92q5SnYfHQjcJGk4WfjcGhG3S7pHUh0gYDnw6VT/DuAkYB3wMnBuBdtmZhUyefJk\nWltb8Tm/2ut481pvVCwUImIFcEQn5cd1UT+AofmEKbMCGTlyZK/e9GUDi+9oNjOznEPBzMxyDgUz\nM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPB\nzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8tVLBQkjZZ0v6SHJK2U9PVUPlXSUknrJP1U0h6p\nfFSaXpfm11eqbWZm1rlKHim8ChwXEYcDM4ATJB0FfAu4MiIOA/4EnJfqnwf8KZVfmeqZmVkVVSwU\nIvNimhyZhgCOA36eym8CPprGT07TpPnvk6RKtc/MzHZV0XMKkoZLWg5sAu4C/gA8HxHtqUorMCmN\nTwKeAkjztwATOlnnHEktklra2toq2Xwzs8KpaChExLaImAFMBmYBb+2HdS6IiMaIaKyrq9vtNpqZ\n2RuqcvVRRDwP3AscDYyTNCLNmgxsSOMbgIMB0vx9gc3VaJ+ZmWUqefVRnaRxaXxP4P3AarJwODVV\nOwf4VRpflKZJ8++JiKhU+8zMbFcjeq7SZwcCN0kaThY+t0bE7ZJWAbdI+ibwe+BHqf6PgJ9IWgf8\nETitgm0zM7NOVCwUImIFcEQn5Y+RnV/YufwV4BOVao+ZmfXMdzSbmVnOoWBmZjmHgpmZ5RwKZmaW\ncyiYmVnOoWBmZjmHgpmZ5RwKZmaWcyiYmVnOoWBmZjmHgpmZ5RwKZmaWcyiYmVnOoWBmZjmHgpmZ\n5RwKZmaWcyiYmVnOoWBmZrmKhYKkgyXdK2mVpJWSLkrlX5O0QdLyNJxUsswlktZJWiPpg5Vqm5mZ\nda5i72gG2oEvRsSDksYCyyTdleZdGRHfLq0sqQE4DZgOHATcLem/RcS2CrbRzMxKVOxIISI2RsSD\naXwrsBqY1M0iJwO3RMSrEfE4sA6YVan2mZnZrqpyTkFSPXAEsDQVfUbSCknXS9ovlU0CnipZrJVO\nQkTSHEktklra2toq2Gozs+KpeChIGgPcBnw+Il4A5gOHAjOAjcB3erO+iFgQEY0R0VhXV9fv7TUz\nK7KKhoKkkWSB0BwRvwCIiGcjYltEbAd+wBtdRBuAg0sWn5zKzMysSip59ZGAHwGrI+K7JeUHllT7\nGPBIGl8EnCZplKSpwDTg/kq1z8zMdlXJq49mA2cBD0tansq+ApwuaQYQwBPA+QARsVLSrcAqsiuX\nLvSVR2Zm1VWxUIiI+wB1MuuObpaZB8yrVJvMzKx7vqPZzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxy\nDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOz\nnEPBzMxyDgUzM8tVLBQkHSzpXkmrJK2UdFEqHy/pLklr0+d+qVySrpa0TtIKSTMr1TYzM+tcJY8U\n2oEvRkQDcBRwoaQGYC6wJCKmAUvSNMCJwLQ0zAHmV7BtZmbWiYqFQkRsjIgH0/hWYDUwCTgZuClV\nuwn4aBo/GfhxZH4HjJN0YKXaZ2ZmuyorFCQdKmlUGj9W0uckjSv3SyTVA0cAS4H9I2JjmvUMsH8a\nnwQ8VbJYayozM7MqKfdI4TZgm6TDgAXAwcA/lbOgpDFp+c9HxAul8yIigCi/uSBpjqQWSS1tbW29\nWdTMzHpQbihsj4h24GPANRHxJaDHrh1JI8kCoTkifpGKn+3oFkqfm1L5BrKw6TA5le0gIhZERGNE\nNNbV1ZXZfDMzK0e5ofC6pNOBc4DbU9nI7haQJOBHwOqI+G7JrEVpPaTPX5WUn52uQjoK2FLSzWRm\nZlUwosx65wKfBuZFxOOSpgI/6WGZ2cBZwMOSlqeyrwCXA7dKOg9YD/xlmncHcBKwDng5faeZmVWR\nsm79XiyQ3VdwcESsqEyTytfY2BgtLS21boaZ2aAiaVlENHY2r9yrj/5D0j6SxgMPAj+Q9N2eljMz\ns8Gl3HMK+6Yrhz5Odi/BkcDxlWuWmZnVQrmhMCJdKfSXvHGi2czMhphyQ+EyYDHwh4h4QNKbgbWV\na5aZmdVCWVcfRcTPgJ+VTD8GnFKpRpmZWW2Ue6J5sqRfStqUhtskTa5048zMrLrK7T66gezmsoPS\n8C+pzMzMhpByQ6EuIm6IiPY03Aj4GRNmZkNMuaGwWdKZkoan4UxgcyUbZmZm1VduKHyK7HLUZ4CN\nwKnAX1WoTWZmViNlhUJErI+Ij0REXUS8KSI+iq8+MjMbcnbnzWtf6LdWmJnZgLA7oaB+a4WZmQ0I\nuxMKvXu8qpmZDXjdhoKkrZJe6GTYSna/wqDU3Az19TBsWPbZ3FzrFpmZDQzdPuYiIsZWqyHV0twM\nc+bAyy9n0+vXZ9MATU21a5eZ2UCwO91Hg9Kll74RCB1efjkrNzMrusKFwpNP9q7czKxIChcKhxzS\nu3IzsyKpWChIuj49UfWRkrKvSdogaXkaTiqZd4mkdZLWSPpgpdo1bx7stdeOZXvtlZWbmRVdJY8U\nbgRO6KT8yoiYkYY7ACQ1AKcB09My35c0vBKNamqCBQtgyhSQss8FC3yS2cwMynzJTl9ExK8l1ZdZ\n/WTgloh4FXhc0jpgFvDbSrStqckhYGbWmVqcU/iMpBWpe2m/VDYJeKqkTmsq24WkOZJaJLW0tbVV\nuq1mZoVS7VCYDxwKzCB72up3eruCiFgQEY0R0VhX51c6mJn1p6qGQkQ8GxHbImI78AOyLiKADcDB\nJVUnpzIzM6uiqoaCpANLJj8GdFyZtAg4TdIoSVOBacD91WybmZlV8ESzpJuBY4GJklqBvwOOlTSD\n7GF6TwDnA0TESkm3AquAduDCiNhWqbaZmVnnFDF4H3ba2NgYLS0ttW6GmdmgImlZRDR2Nq9wdzSb\nmVnXHApmZpZzKJiZWc6hYGZmOYeCmZnlChkKfh2nmVnnKnafwkDl13GamXWtcEcKfh2nmVnXChcK\nfh2nmVnXChcKfh2nmVnXChcKJ53Uu3IzsyIpXCjccUfvys3MiqRwoeBzCmZmXStcKHR17mD8+Oq2\nw8xsICpcKMybByNH7lq+datvYjMzK1woNDXBPvvsWv7aa75XwcyscKEA8Mc/dl7u8wpmVnSFDAXf\nq2Bm1rmKhYKk6yVtkvRISdl4SXdJWps+90vlknS1pHWSVkiaWal2ge9VMDPrSiWPFG4ETtipbC6w\nJCKmAUvSNMCJwLQ0zAHmV7BdvlfBzKwLFQuFiPg1sHPv/cnATWn8JuCjJeU/jszvgHGSDqxU29av\n7125mVlRVPucwv4RsTGNPwPsn8YnAU+V1GtNZbuQNEdSi6SWtra2PjVi+PDOy6U+rc7MbMio2Ynm\niAgg+rDcgohojIjGurq6Pn33tm1drdv3KphZsVU7FJ7t6BZKn5tS+Qbg4JJ6k1NZRUyZ0vW8iy6q\n1LeamQ181Q6FRcA5afwc4Fcl5Wenq5COAraUdDP1u3nzup63eXOlvtXMbOCr5CWpNwO/Bd4iqVXS\necDlwPslrQWOT9MAdwCPAeuAHwB/U6l2gV+7aWbWlYq9ozkiTu9i1vs6qRvAhZVqS2eGDYPt26v5\njWZmA18h72iG7gPBJ5vNrKgKGwpdXZYKPtlsZsVV2FDo6rJU8MlmMyuuwoZCd5elmpkVVWFDobvL\nUsHnFcysmAobCj1dlnr++dVph5nZQFLYUIDuu5BeeslHC2ZWPIUOhZ66kPx6TjMrmkKHQk9dSH6U\ntpkVTaFDAWDChO7nuwvJzIqk8KFw1VXdz/eNbGZWJIUPhaam7DlIXfGNbGZWJIUPBfDlp2ZmHRwK\nwPe/3/38v6nog7zNzAYOh0IZ5s+vdQvMzKrDoZD0dBWSjxbMrAgcCklPVyH5aMHMisChkDQ1wejR\n3dfx0YKZDXUOhRI//GH38320YGZDXU1CQdITkh6WtFxSSyobL+kuSWvT537Vblc5Rwu+w9nMhrJa\nHim8NyJmRERjmp4LLImIacCSNF11PR0tfOpT1WmHmVktDKTuo5OBm9L4TcBHa9GInh6S99prPlow\ns6GrVqEQwL9LWiZpTirbPyI2pvFngP07W1DSHEktklra2toq0rgLLuh+/llnVeRrzcxqrlah8O6I\nmAmcCFwo6X+UzoyIIAuOXUTEgohojIjGurq6ijSupzucI2D69Ip8tZlZTdUkFCJiQ/rcBPwSmAU8\nK+lAgPS5qRZt69DT0cKqVe5GMrOhp+qhIGlvSWM7xoEPAI8Ai4BzUrVzgF9Vu22lejpaAJ90NrOh\npxZHCvsD90l6CLgf+NeIuBO4HHi/pLXA8Wm6pno6WnjtNd/QZmZDi7Lu+8GpsbExWlpaKvodkybB\n0093X+eCC8o7sjAzGwgkLSu5HWAHA+mS1AFpw4ae68yf7/MLZjY0OBTKMGZMz3XOPNPBYGaDn0Oh\nDP/4j+XVczCY2WDnUChDUxO8733l1T3nnJ7rmJkNVA6FMt19NzQ09Fxv2zbYr+qP8jMz6x8OhV5Y\nuRIOOqjnes8/D5IvVzWzwceh0EsbNsDw4eXVnT/fj8Mws8HFodAHN93Uc50Oq1Zl9zqYmQ0GDoU+\naGqChQvLr//001l30p57+uokMxvYHAp91NtgAHjlleyy1eOPr0ybzMx2l0NhN/QlGACWLPGRg5kN\nTA6F3dTUlL1foZzLVXfWceQg+WolMxsYHAr9ZOXK8m9w68r8+W8EhORuJjOrPodCP7r77p4ft90b\nHd1MnQ0jR8LEiTBsGNTXuxvKzPqHQ6Gfff/7WXfS7h419KS9HTZvzr5r/fodu6E8eOjvYcyY7EfI\nzuWjR7/x42TMmP75rrFjs67U0u8bPjz7rK/v/gdQc/OOy02cuGP944/f8bv23DNr+8SJvfuR1dyc\n1Sut39N3DxZ+n0KFTZ+e3atgZtbfRoyAG2/Mzm32ht+nUEMrV2ZXKJV7F7SZWbna2+Gss/r3iMSh\nUAVNTdnOW7gQ9t671q0xs6EkAi69tP/WN+BCQdIJktZIWidpbq3b05+amuDFF7OdGNG/J6XNrLie\nfLL/1jWgQkHScOBa4ESgAThdUh/uABgcOk5KdwwLF8Iee9S6VWY22BxySP+ta0CFAjALWBcRj0XE\na8AtwMk1blPVNDXBq6/uGBSlgeGuJzPbmQTz5vXf+gZaKEwCniqZbk1lOUlzJLVIamlra6tq42pp\n564nDwN3WLgQpkzJ/rFOmJANUla2cGH39adMyboVS6dLl1m4MFufGWRXH/3kJ72/+qg7A+qSVEmn\nAidExF+n6bOAIyPiM53VHwyXpJqZDTSD6ZLUDcDBJdOTU5mZmVXBQAuFB4BpkqZK2gM4DVhU4zaZ\nmRXGiFo3oFREtEv6DLAYGA5cHxEra9wsM7PCGFChABARdwB31LodZmZFNNC6j8zMrIYG1NVHvSWp\nDVjfx8UnAs/1Y3MGA29zMXibi2F3tnlKRNR1NmNQh8LukNTS1SVZQ5W3uRi8zcVQqW1295GZmeUc\nCmZmlityKCyodQNqwNtcDN7mYqjINhf2nIKZme2qyEcKZma2E4eCmZnlChkKQ/HtbpIOlnSvpFWS\nVkq6KJWPl3SXpLXpc79ULklXpz+DFZJm1nYL+k7ScEm/l3R7mp4qaWnatp+m52ghaVSaXpfm19ey\n3X0laZykn0t6VNJqSUcP9f0s6X+mv9ePSLpZ0uihtp8lXS9pk6RHSsp6vV8lnZPqr5V0Tm/bUbhQ\nGMJvd2sHvhgRDcBRwIVpu+YCSyJiGrAkTUO2/dPSMAeYX/0m95uLgNUl098CroyIw4A/Aeel8vOA\nP6XyK1O9wegq4M6IeCtwONm2D9n9LGkS8DmgMSLeTvZctNMYevv5RuCEncp6tV8ljQf+DjiS7KVl\nf9cRJGWLiEINwNHA4pLpS4BLat2uCmznr4D3A2uAA1PZgcCaNH4dcHpJ/bzeYBrIHq++BDgOuB0Q\n2V2eI3be32QPWjw6jY9I9VTrbejl9u4LPL5zu4fyfuaNl2+NT/vtduCDQ3E/A/XAI33dr8DpwHUl\n5TvUK2co3JECZbzdbbBLh8tHAEuB/SNiY5r1DLB/Gh8qfw7fA/4XsD1NTwCej4j2NF26Xfk2p/lb\nUv3BZCrQBtyQusx+KGlvhvB+jogNwLeBJ4GNZPttGUN7P3fo7X7d7f1dxFAY0iSNAW4DPh8RL5TO\ni+ynw5C5BlnSXwCbImJZrdtSRSOAmcD8iDgCeIk3uhSAIbmf9yN7V/tU4CBgb3btZhnyqrVfixgK\nQ/btbpJGkgVCc0T8IhU/K+nANP9AYFMqHwp/DrOBj0h6AriFrAvpKmCcpI7HwpduV77Naf6+wOZq\nNrgftAKtEbE0Tf+cLCSG8n4+Hng8Itoi4nXgF2T7fijv5w693a+7vb+LGApD8u1ukgT8CFgdEd8t\nmbUI6LgC4Ryycw0d5WenqxiOAraUHKYOChFxSURMjoh6sv14T0Q0AfcCp6ZqO29zx5/Fqan+oPpF\nHRHPAE9Jeksqeh+wiiG8n8m6jY6StFf6e96xzUN2P5fo7X5dDHxA0n7pCOsDqax8tT6xUqOTOScB\n/wX8Abi01u3pp216N9mh5QpgeRpOIutLXQKsBe4Gxqf6IrsK6w/Aw2RXdtR8O3Zj+48Fbk/jbwbu\nB9YBPwNGpfLRaXpdmv/mWre7j9s6A2hJ+/qfgf2G+n4Gvg48CjwC/AQYNdT2M3Az2TmT18mOCM/r\ny34FPpW2fR1wbm/b4cdcmJlZrojdR2Zm1gWHgpmZ5RwKZmaWcyiYmVnOoWBmZjmHglknJG2TtLxk\n6Len6UqqL30SptlAMqLnKmaF9OeImFHrRphVm48UzHpB0hOSrpD0sKT7JR2Wyusl3ZOebb9E0iGp\nfH9Jv5T0UBr+e1rVcEk/SO8I+HdJe6b6n1P2TowVkm6p0WZagTkUzDq3507dR58smbclIt4B/B+y\np7QCXAPcFBHvBJqBq1P51cD/jYjDyZ5RtDKVTwOujYjpwPPAKal8LnBEWs+nK7VxZl3xHc1mnZD0\nYkSM6aT8CeC4iHgsPYDwmYiYIOk5sufev57KN0bEREltwOSIeLVkHfXAXZG9OAVJXwZGRsQ3Jd0J\nvEj2+Ip/jogXK7ypZjvwkYJZ70UX473xasn4Nt44v/chsmfazAQeKHkKqFlVOBTMeu+TJZ+/TeO/\nIXtSK0AT8J9pfAlwAeTvkt63q5VKGgYcHBH3Al8me+TzLkcrZpXkXyFmndtT0vKS6TsjouOy1P0k\nrSD7tX96Kvss2dvQvkT2ZrRzU/lFwAJJ55EdEVxA9iTMzgwHFqbgEHB1RDzfb1tkVgafUzDrhXRO\noTEinqt1W8wqwd1HZmaW85GCmZnlfKRgZmY5h4KZmeUcCmZmlnMomJlZzqFgZma5/w8XYGAYu4Px\nHQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jawb7lRer4iW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "23207302-ed8e-4c4c-a51b-9d24cdb46a01"
      },
      "source": [
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, color='darkblue', label='Training acc' )\n",
        "plt.title('Training accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRtxzw31r6mH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "043bfd6f-8d04-4718-ca62-121a931609c9"
      },
      "source": [
        "tempString = 'সরকারি'\n",
        "Y = bornoDict['স']\n",
        "tempInput = np.zeros(shape=(1,10))\n",
        "count = 0\n",
        "for i in tempString:\n",
        "  tempInput[0][count]= ord(i) - 2400\n",
        "  count = count + 1\n",
        "print(tempInput)\n",
        "probability = model.predict(tempInput)\n",
        "print(probability)\n",
        "\n",
        "key_list = list(bornoDict.keys()) \n",
        "val_list = list(bornoDict.values()) \n",
        "probability = np.round(probability)\n",
        "print(probability)  \n",
        "print(key_list[val_list.index(probability)]) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[88. 80. 53. 94. 80. 95.  0.  0.  0.  0.]]\n",
            "[[48.611443]]\n",
            "[[49.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d76ec5e7aef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: array([[49.]], dtype=float32) is not in list"
          ]
        }
      ]
    }
  ]
}